{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYC9b2sTGQ-G"
      },
      "source": [
        "# Neural ODE VAE\n",
        "Implementazione di un Variational AutoEncoder per la ricostruzione, tramite Neural ODE di segnali EEG."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXzvpbFlGk-W"
      },
      "source": [
        "### Colab connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TQCqDsj56ntM",
        "outputId": "553d2a1f-71c5-4be8-8645-4c28a41c621a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting torchdiffeq\n",
            "  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from torchdiffeq) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from torchdiffeq) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy>=1.4.0->torchdiffeq) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.5.0->torchdiffeq) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.5.0->torchdiffeq) (3.0.2)\n",
            "Downloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchdiffeq\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchdiffeq-0.2.5\n",
            "Collecting mne\n",
            "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.15.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.4.26)\n",
            "Downloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.9.0\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45LKrPBOgmAM"
      },
      "source": [
        "### Importing necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH2H9Vs_8cpT",
        "outputId": "b6f9d14f-a138-4a78-e921-1830f70a3397"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-17 10:13:55,390 - INFO - Ora il logging funziona!\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "matplotlib.use('agg')\n",
        "\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "npr.seed(42)\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import logging\n",
        "import logging.config\n",
        "#logging.basicConfig(level=logging.INFO)  # Imposta il livello su INFO\n",
        "# Reset logging se è già stato inizializzato\n",
        "for handler in logging.root.handlers[:]:\n",
        "    logging.root.removeHandler(handler)\n",
        "\n",
        "# Configurazione logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "\n",
        "logging.info(\"Ora il logging funziona!\")\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "#from sklearn.preprocessing import StandardScale\n",
        "\n",
        "import gc\n",
        "import os\n",
        "import glob\n",
        "from torchdiffeq import odeint_adjoint as odeint\n",
        "\n",
        "import time\n",
        "from datetime import datetime as dt\n",
        "\n",
        "import scipy\n",
        "import scipy.signal as signal #per il calcolo della potenza\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import ttest_rel\n",
        "from scipy.stats import pearsonr\n",
        "from scipy.signal import butter, filtfilt\n",
        "#from scipy.integrate import RK45\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "import mne\n",
        "from mne.filter import filter_data\n",
        "from torch.autograd.functional import jacobian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_Is8n4Ogx4t"
      },
      "source": [
        "### Data class\n",
        "`data.py` It describes the class containing the data of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6NBSzfTN9F1T"
      },
      "outputs": [],
      "source": [
        "class Data:\n",
        "    def __init__(self, orig_trajs, samp_trajs, orig_ts, samp_ts, labels=None, device=None):\n",
        "        if device is None: #se il device non è stato assegnato allora usa la CPU\n",
        "            device = 'cpu'\n",
        "        try:\n",
        "            orig_trajs = torch.from_numpy(orig_trajs).float()\n",
        "            samp_trajs = torch.from_numpy(samp_trajs).float()\n",
        "            samp_ts = torch.from_numpy(samp_ts).float()\n",
        "            orig_ts = torch.from_numpy(orig_ts).float()\n",
        "\n",
        "        except Exception:\n",
        "            logging.warning('Inputs cannot be converted to torch (already a torch obj?)\\n'\n",
        "                            f'Types of orig_trajs, samp_trajs, orig_ts, samp_ts: {type(orig_trajs), type(samp_trajs), type(orig_ts), type(samp_ts)} ')\n",
        "\n",
        "        self.samp_ts = samp_ts.to(device)\n",
        "        self.samp_trajs = samp_trajs.to(device)\n",
        "        self.orig_ts = orig_ts.to(device)\n",
        "        self.orig_trajs = orig_trajs.to(device)\n",
        "        self.labels = labels\n",
        "        self.split(orig_trajs, samp_trajs, labels)#splitta i dati tra la parte di training e validation\n",
        "\n",
        "\n",
        "    def get_samp_ts(self):#aggiunta ma da capire se serve o no\n",
        "        return self.samp_ts\n",
        "\n",
        "    @classmethod #possiamo chiamare questo metodo direttamente dalla classe, senza crearne un'istanza\n",
        "    #NB: nei metodi di classe si usa cls per riferirsi alla classe stessa in modo generico\n",
        "    def from_func(cls, func, device, **args):\n",
        "        return cls(*func(**args), device=device)\n",
        "        #Questo metodo chiama la funzione func (in questo caso load_data).load_data restituisce quattro tensori. Questi tensori vengono passati come argomenti alla classe Data, che li usa per creare un'istanza dell'oggetto Data.\n",
        "\n",
        "    def split(self, orig_trajs, samp_trajs, labels, train_split=0.6, val_split=0.2):\n",
        "        # We split the data across the spring dimension [nr. springs, nr. samples, values\n",
        "        train_int = int(train_split * int(orig_trajs.shape[0]))\n",
        "        val_int = int((train_split + val_split) * int(orig_trajs.shape[0]))\n",
        "\n",
        "        # Divisione delle traiettorie campionate\n",
        "        self.samp_trajs_train, self.samp_trajs_val, self.samp_trajs_test = (\n",
        "          samp_trajs[:train_int, :, :],\n",
        "          samp_trajs[train_int:val_int, :, :],\n",
        "          samp_trajs[val_int:, :, :]\n",
        "        )\n",
        "\n",
        "    # Divisione dei tempi campionati\n",
        "\n",
        "\n",
        "        #divisione delle traiettorie originali\n",
        "        self.orig_trajs_train, self.orig_trajs_val, self.orig_trajs_test = (orig_trajs[:train_int, :, :],\n",
        "                                                                            orig_trajs[train_int:val_int, :, :],\n",
        "                                                                            orig_trajs[val_int:, :, :])\n",
        "        #divisione delle traiettorie campionate\n",
        "        self.samp_trajs_train, self.samp_trajs_val, self.samp_trajs_test = (samp_trajs[:train_int, :, :],\n",
        "                                                                            samp_trajs[train_int:val_int, :, :],\n",
        "                                                                            samp_trajs[val_int:, :, :])\n",
        "        #divisione delle etichette, se presenti\n",
        "        if labels:\n",
        "            self.labels_train, self.labels_val, self.labels_test = (labels[:train_int],\n",
        "                                                                    labels[train_int:val_int],\n",
        "                                                                    labels[val_int:])\n",
        "\n",
        "    def compute_validation_metrics(self, model):\n",
        "    # Make sure the model is in evaluation mode\n",
        "      model.eval()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        # Use only the validation set for metric computation\n",
        "        val_trajs = self.samp_trajs_val\n",
        "        val_ts = self.samp_ts_val\n",
        "\n",
        "        # Check if the tensors are on the correct device\n",
        "        if val_trajs.device != model.device:\n",
        "            val_trajs = val_trajs.to(model.device)\n",
        "            val_ts = val_ts.to(model.device)\n",
        "\n",
        "        # Compute model predictions\n",
        "        val_preds = model(val_trajs, val_ts)\n",
        "\n",
        "        # Calculate RMSE\n",
        "        rmse_loss = self.RMSELoss(val_preds, val_trajs)\n",
        "\n",
        "        # Calculate Pearson Correlation\n",
        "        pearson_corr = self.compute_pearson_correlation(val_preds, val_trajs)\n",
        "\n",
        "        # Log and print the results\n",
        "        logging.info(f\"Validation RMSE: {rmse_loss:.4f}, Pearson Correlation: {pearson_corr:.4f}\")\n",
        "        print(f\"Validation RMSE: {rmse_loss:.4f}, Pearson Correlation: {pearson_corr:.4f}\")\n",
        "\n",
        "        return rmse_loss, pearson_corr\n",
        "\n",
        "\n",
        "\n",
        "    def get_train_data(self):\n",
        "        return self.samp_trajs_train, self.samp_ts\n",
        "\n",
        "    def get_val_data(self):\n",
        "        return self.samp_trajs_val, self.samp_ts\n",
        "\n",
        "    def get_test_data(self):\n",
        "        return self.samp_trajs_test, self.samp_ts, self.orig_trajs_test, self.orig_ts\n",
        "\n",
        "    def get_all_data(self):\n",
        "        return self.orig_trajs, self.samp_trajs, self.orig_ts, self.samp_ts\n",
        "\n",
        "    def get_train_labels(self):\n",
        "        return self.labels_train\n",
        "\n",
        "    def get_val_labels(self):\n",
        "        return self.labels_val\n",
        "\n",
        "    def get_test_labels(self):\n",
        "        return self.labels_test\n",
        "\n",
        "    def get_all_labels(self):\n",
        "        return self.labels\n",
        "\n",
        "    @classmethod #metodo che non necessita di un'istanza della classe per essere chiamato\n",
        "    def from_dict(cls, dict, device=None): #a partire da un dizionario dict crea un'istanza della classe\n",
        "        labels = None\n",
        "        if 'labels' in dict:\n",
        "            labels = dict['labels']\n",
        "            logging.info(\"Loading data labels\")\n",
        "\n",
        "        return cls(\n",
        "            dict['orig_trajs'],\n",
        "            dict['samp_trajs'],\n",
        "            dict['orig_ts'],\n",
        "            dict['samp_ts'],\n",
        "            labels,\n",
        "            device\n",
        "        )\n",
        "\n",
        "    def get_dict(self):\n",
        "        return {\n",
        "            'orig_trajs': self.orig_trajs,\n",
        "            'samp_trajs': self.samp_trajs,\n",
        "            'orig_ts': self.orig_ts,\n",
        "            'samp_ts': self.samp_ts,\n",
        "            'labels': self.labels,\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-nqMVnxhFY-"
      },
      "source": [
        "### Visualizer class\n",
        "`visualize.py` definition of the class in order to visualize the plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TiPJSTMf9TJ6"
      },
      "outputs": [],
      "source": [
        "class Visualizer:\n",
        "    def __init__(self,model, data: Data, save_folder: str):\n",
        "        self.model = model\n",
        "        self.data = data\n",
        "        self.save_folder = save_folder + 'png/'\n",
        "        self.device = model.device\n",
        "\n",
        "    def visualize_step(self, version):\n",
        "        now = dt.now().strftime('%H_%M')\n",
        "        fname = f'v{version}_{now}.png'\n",
        "\n",
        "        self.plot_reconstruction(fname)\n",
        "\n",
        "    def visualize_final(self, version, t_pos=np.pi, t_neg=np.pi):\n",
        "        now = dt.now().strftime('%H_%M')\n",
        "        fname = f'{version}_{now}'\n",
        "        self.plot_reconstruction(fname + '_reconstruction.png', t_pos=t_pos, t_neg=t_neg)\n",
        "        self.plot_loss_history(fname + '_loss_history.png')\n",
        "\n",
        "        #tolgo momentaneamnete questi due plot\n",
        "        #self.plot_reconstruction_grid(fname + '_reconstruction_grid.png', t_pos=t_pos, t_neg=t_neg)\n",
        "        #self.plot_original_grid(fname + '_original_grid.png')\n",
        "\n",
        "\n",
        "    def latent_vis(self, fname, z_traj_idx=None, test=True, label=None, saved_data=None):\n",
        "        # We make sure that we plot for the test sample trajectories if test = True\n",
        "        if test:\n",
        "            samp_trajs, samp_ts, orig_trajs, _ = self.data.get_test_data()\n",
        "            #if label is None:\n",
        "                #label = self.data.get_test_labels()\n",
        "        else:\n",
        "            orig_trajs, samp_trajs, _, samp_ts = self.data.get_all_data()\n",
        "            if label is None:\n",
        "                label = self.data.get_all_labels()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if isinstance(self.model, ODEAutoEncoder):\n",
        "                # We forward pass to extract pred_x and z0 (we will only use z0)\n",
        "                if saved_data is not None:\n",
        "                    qz0_mean, qz0_logvar, epsilon = self.model.encode(saved_data)\n",
        "                else:\n",
        "                    qz0_mean, qz0_logvar, epsilon = self.model.encode(samp_trajs)\n",
        "\n",
        "                # Sample z0 (vector) from q(z0)\n",
        "                z0 = self.model.sample_z0(epsilon, qz0_logvar, qz0_mean)\n",
        "                print(\"z0 size\", z0.size())\n",
        "\n",
        "                #from sklearn.manifold import TSNE\n",
        "\n",
        "                #print(\"Applying t-SNE to latent vectors...\")\n",
        "                #tsne = TSNE(n_components=2, perplexity=30, learning_rate='auto', init='pca', random_state=42)\n",
        "                #z0_red = tsne.fit_transform(z0.cpu().numpy())\n",
        "\n",
        "\n",
        "                pca = PCA(n_components=2)\n",
        "                pca.fit(z0)\n",
        "                print(\"Explained variance:\", pca.explained_variance_ratio_)\n",
        "                z0_red = pca.fit_transform(z0)\n",
        "\n",
        "                # print(z0_red.shape)\n",
        "                print(z0_red[:, 0].shape)\n",
        "                #print(len(label))\n",
        "\n",
        "                # df=pd.DataFrame(z0_red,label)\n",
        "                d = {'PC1': z0_red[:, 0], 'PC2': z0_red[:, 1], 'Label': label}\n",
        "                df = pd.DataFrame(d)\n",
        "\n",
        "                # print(len(df[df.Label==3].PC1))\n",
        "\n",
        "                # z0 latent space plot\n",
        "                if label is not None:\n",
        "                  plt.figure()\n",
        "    # z0 samples in 2D\n",
        "                  colors = [\"red\", \"green\", \"blue\", \"purple\", \"orange\"]\n",
        "                  condition_names = {\n",
        "                    0: \"baseline\",\n",
        "                    1: \"vr1\",\n",
        "                    2: \"vr2\",\n",
        "                    3: \"vr3\",\n",
        "                    4: \"vr4\"\n",
        "                  }\n",
        "                  for i in np.unique(label):\n",
        "                    plt.plot(\n",
        "                      df[df.Label == i].PC1,\n",
        "                      df[df.Label == i].PC2,\n",
        "                      'o',\n",
        "                      color=colors[i],\n",
        "                      label=f'Condition: {condition_names.get(i, str(i))}',\n",
        "                      linewidth=2,\n",
        "                      zorder=1\n",
        "                    )\n",
        "                    plt.legend()\n",
        "                else:\n",
        "                  plt.figure()\n",
        "                  plt.plot(\n",
        "                    z0_red[:, 0],\n",
        "                    z0_red[:, 1],\n",
        "                    'o',\n",
        "                    label='z0 samples in 2D',\n",
        "                    linewidth=2,\n",
        "                    zorder=1\n",
        "                    )\n",
        "                  plt.legend()\n",
        "\n",
        "                logging.info('Saved reconstruction at {}'.format(self.save_folder + fname))\n",
        "                plt.savefig(self.save_folder + 'z0' + fname, dpi=250)\n",
        "                if z_traj_idx is not None:\n",
        "                    ts_rmse = torch.from_numpy(np.linspace(0., torch.max(samp_ts), num=len(samp_ts))).to(self.device)\n",
        "                    pred_x, pred_z = self.model.decode(z0, ts_rmse, return_z=True)\n",
        "\n",
        "                    # print(pred_z.size())\n",
        "                    # print(pred_z)\n",
        "\n",
        "                    pca_z = PCA(n_components=2)\n",
        "                    pca_z.fit(pred_z[z_traj_idx, :, :])\n",
        "                    print(pca_z.explained_variance_ratio_)\n",
        "                    pred_z_red = pca_z.fit_transform(pred_z[z_traj_idx, :, :])\n",
        "                    print(pred_z_red.shape)\n",
        "\n",
        "                    stype = label[z_traj_idx]\n",
        "                    print(stype)\n",
        "                    plt.figure()\n",
        "                    plt.plot(pred_z_red[:, 0], pred_z_red[:, 1], 'o', color=colors[stype],\n",
        "                             label=f'latent traj Spring type {stype}', linewidth=2,\n",
        "                             zorder=1)\n",
        "                    plt.legend()\n",
        "\n",
        "                    logging.info('Saved reconstruction at {}'.format(self.save_folder + fname))\n",
        "                    plt.savefig(self.save_folder + 'z_traj' + fname, dpi=250)\n",
        "\n",
        "            elif isinstance(self.model, LSTMAutoEncoder):\n",
        "                logging.info('Cannot sample latent space from Autoencoder baseline')\n",
        "\n",
        "\n",
        "    def plot_reconstruction(self, fname, t_pos=np.pi, t_neg=np.pi, idx=0, test=False, toy=False):\n",
        "        orig_trajs, samp_trajs, _, samp_ts = self.data.get_all_data()# We unwrap the trajectories from the data object\n",
        "        #print(\"Valori asse x tempo: \",orig_trajs[idx, :, 0])\n",
        "\n",
        "        # We make sure that we plot for the test sample trajectories if test = True\n",
        "        if test: #la variabile test viene attivata per distinguere tra la modalità di addestramento o test\n",
        "            samp_trajs, samp_ts, orig_trajs, _ = self.data.get_test_data()\n",
        "\n",
        "        with torch.no_grad(): #PyTorch non memorizza i gradienti intermedi necessari per la backpropagation\n",
        "            if isinstance(self.model, ODEAutoEncoder): #controlla se il modello è un ODEAutoEncoder\n",
        "\n",
        "                qz0_mean, qz0_logvar, epsilon = self.model.encode(samp_trajs)# We forward pass to extract pred_x and z0 (we will only use z0)\n",
        "\n",
        "                z0 = self.model.sample_z0(epsilon, qz0_logvar, qz0_mean)# Sample z0 (vector) from q(z0)\n",
        "\n",
        "                # We generate new linspaces for extrapolation and negative extrapolation | We use the decode function to extract pred_x\n",
        "                #ts_rmse = torch.from_numpy(np.linspace(1., torch.max(samp_ts).cpu().item(), num=len(samp_ts))).to(self.device)\n",
        "\n",
        "                #ricostruzione\n",
        "                ts_rec=samp_ts\n",
        "                pred_x_rec=self.model.decode(z0,ts_rec)\n",
        "\n",
        "            # Creiamo una finestra temporale per l'extrapolazione\n",
        "                extrapolation_window = 10  # Numero di passi di extrapolazione\n",
        "                num_extra_points = 3  # Quanti punti generare nell'extrapolazione\n",
        "\n",
        "            # Creiamo la sequenza temporale per l'extrapolazione (pochi punti, non equidistanti)\n",
        "                ts_max = torch.max(samp_ts).cpu().item()\n",
        "                ts_extra = np.linspace(ts_max, ts_max + extrapolation_window, num=num_extra_points)\n",
        "                ts_extra = torch.from_numpy(ts_extra).to(self.device)\n",
        "\n",
        "            # Generiamo la traiettoria extrapolata con pochi punti\n",
        "                pred_x_pos = self.model.decode(z0, ts_extra)\n",
        "\n",
        "                #ts_pos = torch.from_numpy(np.linspace(0, torch.max(samp_ts).cpu().item() + t_pos, num=int(len(samp_ts)))).to(self.device)\n",
        "\n",
        "\n",
        "                #pred_x_pos = self.model.decode(z0, ts_pos)\n",
        "                #pred_x_rmse = self.model.decode(z0, ts_rmse)\n",
        "\n",
        "                #val = int((t_pos / (torch.max(samp_ts) + t_pos)) * len(samp_ts)) #numero di punti di estrapolazione\n",
        "                #pred_x_rec = pred_x_pos[:, :(len(samp_ts) - val), :]\n",
        "                #pred_x_pos = pred_x_pos[:, (len(samp_ts) - val - 1):, :]\n",
        "                #pred_x_rec=pred_x_pos[:,:]\n",
        "\n",
        "\n",
        "                pred_x_pos = pred_x_pos.cpu().detach().numpy()\n",
        "                pred_x_rec = pred_x_rec.cpu().detach().numpy()\n",
        "\n",
        "                # We plot only the first trajectory\n",
        "                orig_trajs = orig_trajs.cpu().detach()\n",
        "                samp_trajs = samp_trajs.cpu().detach()\n",
        "\n",
        "                if (t_neg > 0):\n",
        "                    ts_neg = torch.from_numpy(np.linspace(-t_neg, 0., num=int(len(samp_ts) / 8))[::-1].copy()).to(\n",
        "                        self.device)\n",
        "                    pred_x_neg = torch.flip(self.model.decode(z0, ts_neg), dims=[1]).cpu().detach().numpy()\n",
        "\n",
        "                    plt.figure()\n",
        "                    plt.plot(orig_trajs[idx, :, 0].cpu().numpy(), orig_trajs[idx, :, 1].cpu().numpy(), 'g', label='True trajectory', linewidth=2,\n",
        "                             zorder=1)\n",
        "\n",
        "                    if isinstance(pred_x_rec, torch.Tensor):\n",
        "                        pred_x_rec = pred_x_rec.cpu().numpy()\n",
        "\n",
        "                    plt.plot(pred_x_rec[idx, :, 0], pred_x_rec[idx, :, 1], '-o', color='r', markersize=3,label='Reconstruction', zorder=3)\n",
        "\n",
        "                    if isinstance(pred_x_pos, torch.Tensor):\n",
        "                        pred_x_pos = pred_x_pos.cpu().numpy()\n",
        "\n",
        "                    #plt.plot(pred_x_pos[idx, :, 0], pred_x_pos[idx, :, 1], '-o', color='c', markersize=3,\n",
        "                    #label='Learned trajectory (t>0)', zorder=2)\n",
        "\n",
        "                  # Se pred_x_neg è un tensore, converti in NumPy\n",
        "                    if isinstance(pred_x_neg, torch.Tensor):\n",
        "                        pred_x_neg = pred_x_neg.cpu().numpy()\n",
        "\n",
        "                    #plt.plot(pred_x_neg[idx, :, 0], pred_x_neg[idx, :, 1], '-o', color='c', markersize=3,\n",
        "                    #label='Learned trajectory (t<0)', zorder=2)\n",
        "                    plt.scatter(samp_trajs[idx, :, 0].cpu().numpy(), samp_trajs[idx, :, 1].cpu().numpy(), color='b', label='Sampled data', s=10,\n",
        "                                zorder=2)\n",
        "                    plt.legend()\n",
        "                else:\n",
        "                    plt.figure()\n",
        "                    plt.plot(orig_trajs[idx, :, 0].cpu().numpy(), orig_trajs[idx, :, 1].cpu().numpy(), 'g', label='True trajectory', zorder=1)\n",
        "                    plt.plot(pred_x_rec[idx, :, 0], pred_x_rec[idx, :, 1], '-o', color = 'r', markersize = 3, label='Reconstruction', zorder=3)\n",
        "                    #plt.plot(pred_x_pos[idx, :, 0].cpu().numpy(), pred_x_pos[idx, :, 1].cpu().numpy(), '-o', color='c', markersize=3,\n",
        "                             #label='Learned trajectory (t>0)', zorder=3)\n",
        "                    plt.scatter(samp_trajs[idx, :, 0].cpu().numpy(), samp_trajs[idx, :, 1].cpu().numpy(), color='b', label='Sampled data', s=3,\n",
        "                                zorder=2)\n",
        "                    plt.legend()\n",
        "\n",
        "            elif isinstance(self.model, LSTMAutoEncoder):\n",
        "                pred_x = self.model.forward(samp_trajs)\n",
        "\n",
        "                plt.figure()\n",
        "                plt.plot(orig_trajs[idx, orig_trajs[idx, :, 0] >= 0, 0].cpu().numpy(), orig_trajs[idx, orig_trajs[idx, :, 0] >= 0, 1].cpu().numpy(), 'g', label='true trajectory', zorder=1)\n",
        "                plt.plot(pred_x[idx, :, 0].cpu().numpy(), pred_x[idx, :, 1].cpu().numpy(), 'r', label='learned trajectory (t>0)', zorder=3)\n",
        "                plt.scatter(samp_trajs[idx, :, 0].cpu().numpy(), samp_trajs[idx, :, 1].cpu().numpy(), color='b', label='sampled data', s=3,\n",
        "                            zorder=2)\n",
        "                plt.legend()\n",
        "\n",
        "        if not os.path.exists(self.save_folder):\n",
        "          os.makedirs(self.save_folder)\n",
        "        #logging.info('Saved reconstruction at {}'.format(self.save_folder + fname))\n",
        "        plt.savefig(self.save_folder + fname, dpi=250)\n",
        "\n",
        "        # Definisci la cartella per salvare le finestre ricostruite\n",
        "        if combined_channels==3:\n",
        "          save_dir = f\"./Reconstructions/windowsize{window_size}/overlap{overlap}/SUB{subject}/condition{condition}/band{band}/channels_{channel}_{channel+1}_{channel+2}\"\n",
        "        if combined_channels==1:\n",
        "          save_dir = f\"./Reconstructions/windowsize{window_size}/overlap{overlap}/SUB{subject}/condition{condition}/band{band}/channel{channel}\"\n",
        "        if combined_channels==7:\n",
        "          save_dir = f\"/./Reconstructions/windowsize{window_size}/overlap{overlap}/SUB{subject}/condition{condition}/band{band}/channels_{channel}_{channel+1}_{channel+2}_{channel+3}_{channel+4}_{channel+5}_{channel+6}\"\n",
        "\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        if crossed==False: #per salvare solo la ricostruzione finale\n",
        "          np.save(f\"{save_dir}/final_reconstruction.npy\", pred_x_rec if isinstance(pred_x_rec, np.ndarray) else pred_x_rec.cpu().detach().numpy())\n",
        "\n",
        "        if crossed==True: #per salvare tutte le ricostruzioni\n",
        "          npy_name = fname.replace(\"reconstruction\", \"final_reconstruction\").replace(\".png\", \".npy\")\n",
        "          reconstruction = pred_x_rec[idx]  # shape: (window_size, 2)\n",
        "          save_dir = os.path.join(\n",
        "            \"./Reconstructions\",\n",
        "            f\"windowsize{window_size}\",\n",
        "            f\"/overlap{overlap}\"\n",
        "            f\"/SUB{subject}\",\n",
        "            f\"/condition{condition}\",\n",
        "            f\"/band{band}\",\n",
        "            f\"/channel{channel}\",\n",
        "            f\"/idx{idx}\"\n",
        "          )\n",
        "          os.makedirs(save_dir, exist_ok=True)\n",
        "          np.save(os.path.join(save_dir, npy_name), reconstruction)\n",
        "\n",
        "\n",
        "        #np.save(f\"./final_reconstruction_{band}_{channel}.npy\",pred_x_rec if isinstance(pred_x_rec, np.ndarray) else pred_x_rec.cpu().detach().numpy())\n",
        "\n",
        "\n",
        "\n",
        "    def plot_reconstruction_grid(self, fname, t_pos=np.pi, t_neg=np.pi, size=5, test=False):\n",
        "        # We unwrap the trajectories from the data object\n",
        "        orig_trajs, samp_trajs, _, samp_ts = self.data.get_all_data()\n",
        "\n",
        "        # We make sure that we plot for the test sample trajectories if test = True\n",
        "        if test:\n",
        "            samp_trajs, samp_ts, orig_trajs, _ = self.data.get_test_data()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if isinstance(self.model, ODEAutoEncoder):\n",
        "                # We forward pass to extract pred_x and z0 (we will only use z0)\n",
        "                qz0_mean, qz0_logvar, epsilon = self.model.encode(samp_trajs)\n",
        "\n",
        "                # Sample z0 (vector) from q(z0)\n",
        "                z0 = self.model.sample_z0(epsilon, qz0_logvar, qz0_mean)\n",
        "\n",
        "                # We generate new linspaces for extrapolation and negative extrapolation | We use the decode function to extract pred_x\n",
        "            # Converte torch.max(samp_ts) in un numero scalare prima di passarlo a NumPy\n",
        "                max_samp_ts = torch.max(samp_ts).cpu().item()\n",
        "\n",
        "                ts_pos = torch.from_numpy(np.linspace(0., max_samp_ts + t_pos, num=len(samp_ts))).to(self.device)\n",
        "                pred_x_pos = self.model.decode(z0, ts_pos).cpu().detach().numpy()\n",
        "\n",
        "                if t_neg > 0:\n",
        "                    ts_neg = torch.from_numpy(np.linspace(-t_neg, 0., num=int(len(samp_ts) / 8))[::-1].copy()).to(\n",
        "                        self.device)\n",
        "                    pred_x_neg = torch.flip(self.model.decode(z0, ts_neg), dims=[1]).cpu().detach().numpy()\n",
        "\n",
        "                # Define extrapolation\n",
        "                #val = int((t_pos / (torch.max(samp_ts) + t_pos)) * len(samp_ts))\n",
        "                val=0\n",
        "                pred_x_rec = pred_x_pos[:, :(len(samp_ts) - val), :]\n",
        "                pred_x_pos = pred_x_pos[:, (len(samp_ts) - val - 1):, :]\n",
        "\n",
        "                orig_trajs = orig_trajs.cpu().detach()\n",
        "                samp_trajs = samp_trajs.cpu().detach()\n",
        "\n",
        "                plt.figure(figsize=(15, 15))\n",
        "                for i in range(size ** 2):\n",
        "                    # We scale all y values to be 0:1\n",
        "                    min_traj_y = np.min(orig_trajs.numpy()[i, :, 1])\n",
        "                    max_traj_y = np.max(orig_trajs.numpy()[i, :, 1])\n",
        "                    pred_x_rec_plt_y = (pred_x_rec[i, :, 1] - min_traj_y) / (max_traj_y - min_traj_y)\n",
        "                    pred_x_pos_plt_y = (pred_x_pos[i, :, 1] - min_traj_y) / (max_traj_y - min_traj_y)\n",
        "                    orig_trajs_plt_y = (orig_trajs[i, :, 1] - min_traj_y) / (max_traj_y - min_traj_y)\n",
        "\n",
        "                    # We scale all x values to be 0:1\n",
        "                    min_traj_x = np.min(orig_trajs.numpy()[i, :, 0])\n",
        "                    max_traj_x = np.max(orig_trajs.numpy()[i, :, 0])\n",
        "                    pred_x_rec_plt_x = (pred_x_rec[i, :, 0] - min_traj_x) / (max_traj_x - min_traj_x)\n",
        "                    pred_x_pos_plt_x = (pred_x_pos[i, :, 0] - min_traj_x) / (max_traj_x - min_traj_x)\n",
        "                    orig_trajs_plt_x = (orig_trajs[i, :, 0] - min_traj_x) / (max_traj_x - min_traj_x)\n",
        "\n",
        "                    plt.subplot(size, size, i + 1)\n",
        "                    plt.plot(pred_x_rec_plt_x, pred_x_rec_plt_y, '-o', color='r', markersize=1, label='Reconstruction',\n",
        "                             zorder=3)\n",
        "                    plt.plot(orig_trajs_plt_x, orig_trajs_plt_y, color='g', linewidth=1, label='True trajectory',\n",
        "                             markersize=1, zorder=1)\n",
        "                    #if t_pos > 0:\n",
        "                        #plt.plot(pred_x_pos_plt_x, pred_x_pos_plt_y, '-o', color='c', markersize=3,\n",
        "                                 #label='Learned trajectory (t>0)', zorder=2)\n",
        "                    #if t_neg > 0:\n",
        "                        #pred_x_neg_plt_y = (pred_x_neg[i, :, 1] - min_traj_y) / (max_traj_y - min_traj_y)\n",
        "                        #pred_x_neg_plt_x = (pred_x_neg[i, :, 0] - min_traj_x) / (max_traj_x - min_traj_x)\n",
        "                        #plt.plot(pred_x_neg_plt_x, pred_x_neg_plt_y, '-o', color='c', markersize=3,\n",
        "                                 #label='Learned trajectory (t<0)', zorder=2)\n",
        "\n",
        "                plt.legend(\n",
        "                    #['Reconstruction', 'True trajectory', 'Learned trajectory (t>0)', 'Learned trajectory (t<0)'])\n",
        "                    ['Reconstruction', 'True trajectory'])\n",
        "\n",
        "            elif isinstance(self.model, LSTMAutoEncoder):\n",
        "                pred_x = self.model.forward(samp_trajs)\n",
        "\n",
        "                plt.figure(figsize=(15, 15))\n",
        "\n",
        "                for i in range(size ** 2):\n",
        "                    plt.subplot(size, size, i + 1)\n",
        "                    plt.plot(orig_trajs[i, :, 0], orig_trajs[i, :, 1], 'g', label='true trajectory', zorder=1)\n",
        "                    plt.plot(pred_x[i, :, 0], pred_x[i, :, 1], 'r', label='learned trajectory (t>0)', zorder=3)\n",
        "                    plt.scatter(samp_trajs[i, :, 0], samp_trajs[i, :, 1], color='b', label='sampled data', s=3,\n",
        "                                zorder=2)\n",
        "                plt.legend()\n",
        "\n",
        "            #logging.info('Saved reconstruction grid plot at {}'.format(self.save_folder + fname))\n",
        "            plt.savefig(self.save_folder + fname, dpi=250)\n",
        "\n",
        "    def plot_original_grid(self, fname):\n",
        "        # We unwrap the trajectories from the data object\n",
        "        orig_trajs, _, _, _ = self.data.get_all_data()\n",
        "\n",
        "        orig_trajs = orig_trajs.cpu().detach()\n",
        "\n",
        "        plt.figure(figsize=(15, 15))\n",
        "        for i in range(25):\n",
        "            plt.subplot(5, 5, i + 1)\n",
        "            plt.scatter(x=orig_trajs[i, :, 0], y=orig_trajs[i, :, 1], color='b')\n",
        "\n",
        "        plt.legend(['orig_trajs'])\n",
        "\n",
        "        #logging.info('Saved original grid plot at {}'.format(self.save_folder + fname))\n",
        "        plt.savefig(self.save_folder + fname, dpi=250)\n",
        "\n",
        "    def plot_loss_history(self, fname):\n",
        "        plt.figure(figsize=(15, 15))\n",
        "        plt.plot(self.model.train_loss, color='b')\n",
        "        plt.plot(self.model.val_loss, color='r')\n",
        "\n",
        "        plt.legend(['train ELBO', 'validation ELBO'])\n",
        "\n",
        "        #logging.info('Saved loss plot at {}'.format(self.save_folder + fname))\n",
        "        plt.savefig(self.save_folder + fname, dpi=250)\n",
        "\n",
        "    def plot_latent_space(self, fname):\n",
        "        # We unwrap the trajectories from the data object\n",
        "        orig_trajs, samp_trajs, orig_ts, samp_ts = self.data.get_all_data()\n",
        "\n",
        "        # We forward pass to extract pred_x and z0\n",
        "        pred_x, z0 = self.model.forward(samp_trajs, samp_ts, return_z0=True)\n",
        "\n",
        "        # We use the decode function to extract pred_z\n",
        "        pred_z = self.model.decode(z0, samp_ts, return_z=True)\n",
        "\n",
        "        # Dunno if this is necessary\n",
        "        pred_z = pred_z.cpu().detach().numpy()\n",
        "\n",
        "        # We create the plot\n",
        "        plt.figure(figsize=(15, 15))\n",
        "        for i in range(9):\n",
        "            plt.subplot(3, 3, i + 1)\n",
        "            plt.scatter(x=pred_z[i, :, 0], y=pred_z[i, :, 1], color='r')\n",
        "        plt.legend(['pred_z,'])\n",
        "        plt.savefig(fname, dpi=250)\n",
        "        plt.show()\n",
        "\n",
        "    def plot_extrapolation(self):\n",
        "        pass\n",
        "\n",
        "    def RMSELoss(self, yhat, y):\n",
        "        assert type(yhat) == torch.Tensor\n",
        "        assert type(y) == torch.Tensor\n",
        "        if y.device != yhat.device:\n",
        "          y = y.to(yhat.device)\n",
        "\n",
        "        return torch.sqrt(torch.mean((yhat - y) ** 2))\n",
        "\n",
        "    def compute_means(self, yhat, y):\n",
        "      #verifica che entrambi gli input siano tensori PyTorch\n",
        "        assert isinstance(yhat, torch.Tensor)\n",
        "        assert isinstance(y, torch.Tensor)\n",
        "\n",
        "        mean_yhat = torch.mean(yhat)\n",
        "        mean_y = torch.mean(y)\n",
        "\n",
        "        return mean_yhat, mean_y\n",
        "\n",
        "    def compute_var(self,yhat,y):\n",
        "        assert isinstance(yhat,torch.Tensor)\n",
        "        assert isinstance(y,torch.Tensor)\n",
        "\n",
        "        var_yhat = torch.var(yhat, unbiased=False)  # Varianza di yhat\n",
        "        var_y = torch.var(y, unbiased=False)  # Varianza di y\n",
        "\n",
        "        return var_yhat, var_y\n",
        "\n",
        "    def compute_pearson_correlation(self, yhat, y): #misura la correlazione lineare tra due tensori (valore tra -1 e 1)\n",
        "    #controlla che entrambi gli input siano tensori PyTorch\n",
        "        assert isinstance(yhat, torch.Tensor)\n",
        "        assert isinstance(y, torch.Tensor)\n",
        "        if y.device != yhat.device:\n",
        "          y = y.to(yhat.device)\n",
        "\n",
        "        #calcolo medie\n",
        "        x_mean = torch.mean(yhat)\n",
        "        y_mean = torch.mean(y)\n",
        "        #print(\"La forma di yhat e y è: \", yhat.shape, y.shape)\n",
        "\n",
        "        #centratura\n",
        "        x_diff = yhat - x_mean\n",
        "        y_diff = y - y_mean\n",
        "\n",
        "        #calcolo del numeratore della formula di Pearson\n",
        "        numerator = torch.sum(x_diff * y_diff)\n",
        "        denominator = torch.sqrt(torch.sum(x_diff ** 2) * torch.sum(y_diff ** 2)) #radice quadrata del prodotto delle varianze\n",
        "\n",
        "        correlation = numerator / (denominator + 1e-8)  # Per evitare divisioni per zero\n",
        "        return correlation\n",
        "\n",
        "\n",
        "    def computeRMSE_VAE(self, samp_trajs, samp_ts):\n",
        "        with torch.no_grad():\n",
        "            pred_x_rmse = self.model.forward(samp_trajs, samp_ts)\n",
        "            rmse_loss = self.RMSELoss(pred_x_rmse, samp_trajs)\n",
        "\n",
        "            return (rmse_loss.cpu().detach().numpy(), pred_x_rmse)\n",
        "\n",
        "    def computeRMSE_AE(self, samp_trajs):\n",
        "        with torch.no_grad():\n",
        "            pred_x_rmse = self.model.forward(samp_trajs)\n",
        "            rmse_loss = self.RMSELoss(pred_x_rmse, samp_trajs)\n",
        "\n",
        "            return (rmse_loss.cpu().detach().numpy(), pred_x_rmse)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzNZBp1ihTl9"
      },
      "source": [
        "### Definition of the MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q7jNhTXjuht9"
      },
      "outputs": [],
      "source": [
        "###########################################\n",
        "# UTILITY FUNCTIONS\n",
        "###########################################\n",
        "\n",
        "def log_normal_pdf(x, mean, logvar):\n",
        "    const = torch.from_numpy(np.array([2. * np.pi])).float().to(x.device)\n",
        "    const = torch.log(const)\n",
        "    return -.5 * (const + logvar + (x - mean) ** 2. / torch.exp(logvar))\n",
        "\n",
        "def normal_kl(mu1, lv1, mu2, lv2):\n",
        "    v1 = torch.exp(lv1)\n",
        "    v2 = torch.exp(lv2)\n",
        "    lstd1 = lv1 / 2.\n",
        "    lstd2 = lv2 / 2.\n",
        "\n",
        "    kl = lstd2 - lstd1 + ((v1 + (mu1 - mu2) ** 2.) / (2. * v2)) - .5\n",
        "    return kl\n",
        "\n",
        "\n",
        "###########################################\n",
        "# ABSTRACT TRAINER MODEL\n",
        "###########################################\n",
        "\n",
        "class TrainerModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "        self.epoch_time = []\n",
        "\n",
        "    def train_step(self, x, t):\n",
        "        x = x.to(self.device)  # Assicura che x sia su GPU\n",
        "        t = t.to(self.device)  # Assicura che t sia su GPU\n",
        "\n",
        "        pred_x = self.forward(x)\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @classmethod\n",
        "    def from_checkpoint(cls, path):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_params(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_args(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_state_dicts(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "###########################################\n",
        "# ODE IMPLEMENTATION --> definisce l'ODE latente dz(t)/dt=f\n",
        "###########################################\n",
        "\n",
        "class LatentODEfunc(nn.Module):\n",
        "    def __init__(self, latent_dim=4, nhidden=20): #implementato come una rete neurale (ELU+MLP)\n",
        "        super(LatentODEfunc, self).__init__()\n",
        "        self.elu = nn.ELU(inplace=True)\n",
        "        self.fc1 = nn.Linear(latent_dim, nhidden)\n",
        "        self.fc2 = nn.Linear(nhidden, nhidden)\n",
        "        self.fc3 = nn.Linear(nhidden, latent_dim)\n",
        "        self.nfe = 0\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.elu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.elu(out)\n",
        "        out = self.fc3(out)\n",
        "\n",
        "        if out.requires_grad:\n",
        "            self.nfe += 1\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "###########################################\n",
        "# ENCODER IMPLEMENTATION--> RNN oppure LSTM, apprende la distribuzione q(z0) dello stato latente\n",
        "###########################################\n",
        "\n",
        "class RecognitionRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, latent_dim=4, obs_dim=2, nhidden=25):\n",
        "        super(RecognitionRNN, self).__init__()\n",
        "        #logging.info('Setting up RNN')\n",
        "        self.nhidden = nhidden\n",
        "        self.i2h = nn.Linear(obs_dim + nhidden, nhidden)\n",
        "        self.h2o = nn.Linear(nhidden, latent_dim * 2)\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        combined = torch.cat((x, h), dim=1)\n",
        "        h = torch.tanh(self.i2h(combined))\n",
        "        out = self.h2o(h)\n",
        "        return out, h\n",
        "\n",
        "    def forward_sequence(self, x, device):\n",
        "        h = self.init_hidden(batch=x.shape[0]).to(device)\n",
        "\n",
        "        # Forward pass over all inputs for each time step\n",
        "        # in reverse so we get z0 instead of z_T\n",
        "        for t in reversed(range(x.size(1))):\n",
        "            obs = x[:, t, :]\n",
        "            out, h = self.forward(obs, h)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def init_hidden(self, batch):\n",
        "        return torch.zeros(batch, self.nhidden)\n",
        "\n",
        "\n",
        "class LSTMEncoder(nn.Module):\n",
        "    def __init__(self, input_size, nhidden, latent_dim):\n",
        "        super(LSTMEncoder, self).__init__()\n",
        "        self.nhidden = nhidden\n",
        "        self.lstm = nn.LSTMCell(input_size, nhidden) #ho inserito 1 al posto di input_size\n",
        "        self.h2o = nn.Linear(nhidden, latent_dim * 2)\n",
        "\n",
        "    def forward(self, x, h, c):\n",
        "        hn, cn = self.lstm(x, (h, c))\n",
        "        out = self.h2o(hn)\n",
        "        return out, hn, cn\n",
        "\n",
        "    def forward_sequence(self, x, device):\n",
        "        x = x.to(device)  #Sposta x su GPU\n",
        "\n",
        "        h, c = self.init_hidden(batch=x.shape[0])\n",
        "        h = h.to(device)  #Sposta hidden state su GPU\n",
        "        c = c.to(device)\n",
        "        hn = h.to(device)\n",
        "        cn = c.to(device)\n",
        "        cn = cn[0, :, :]\n",
        "        hn = hn[0, :, :]\n",
        "        # Forward pass over all inputs for each time step\n",
        "        # in reverse so we get z0 instead of z_T\n",
        "        for t in reversed(range(x.size(1))):\n",
        "            obs = x[:, t, :].to(device)\n",
        "            out, hn, cn = self.forward(obs, hn, cn)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def init_hidden(self, batch):\n",
        "        h = torch.zeros(1, batch, self.nhidden)\n",
        "        c = torch.zeros(1, batch, self.nhidden)\n",
        "        return [h, c]\n",
        "\n",
        "\n",
        "class LSTMBaseline(nn.Module):\n",
        "    def __init__(self, input_size, nhidden, latent_dim):\n",
        "        super(LSTMBaseline, self).__init__()\n",
        "        self.nhidden = nhidden\n",
        "        self.latent_dim = latent_dim\n",
        "        self.lstm = nn.LSTMCell(input_size, nhidden)\n",
        "        self.lstm2 = nn.LSTMCell(nhidden, latent_dim)\n",
        "        # self.activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x, h1, c1, h2, c2):\n",
        "        # Map inputs to hidden state from x -> h1\n",
        "        # Map hidden state to latent dimension h1 -> h2\n",
        "        x = x.to(self.device)  # Sposta x su GPU\n",
        "        h1 = h1.to(self.device)  # Sposta h1 su GPU\n",
        "        c1 = c1.to(self.device)  # Sposta c1 su GPU\n",
        "        h2 = h2.to(self.device)  #Sposta h2 su GPU\n",
        "        c2 = c2.to(self.device)\n",
        "\n",
        "        hn1, cn1 = self.lstm(x, (h1, c1))\n",
        "        hn2, cn2 = self.lstm2(hn1, (h2, c2))\n",
        "        return hn1, cn1, hn2, cn2\n",
        "\n",
        "    def forward_sequence(self, x, device):\n",
        "        h1, c1, h2, c2 = self.init_hidden(batch=x.shape[0])\n",
        "        h1 = h1.to(device)\n",
        "        c1 = c1.to(device)\n",
        "\n",
        "        output = []\n",
        "        # Forward pass over all inputs for each time step\n",
        "        for t in range(x.size(1)):\n",
        "            obs = x[:, t, :]\n",
        "            h1, c1, h2, c2 = self.forward(obs, h1, c1, h2, c2)\n",
        "            output.append(h2)\n",
        "\n",
        "        output = torch.stack(output, dim=1)\n",
        "        return output\n",
        "\n",
        "    def init_hidden(self, batch):\n",
        "        h = torch.zeros(1, batch, self.nhidden)\n",
        "        c = torch.zeros(1, batch, self.nhidden)\n",
        "        c1 = c[0, :, :]\n",
        "        h1 = h[0, :, :]\n",
        "\n",
        "        h = torch.zeros(1, batch, self.latent_dim)\n",
        "        c = torch.zeros(1, batch, self.latent_dim)\n",
        "        c2 = c[0, :, :]\n",
        "        h2 = h[0, :, :]\n",
        "        return h1, c1, h2, c2\n",
        "\n",
        "\n",
        "###########################################\n",
        "# DECODER IMPLEMENTATION--> ricostruisce le traiettorie a partire dallo stato latente\n",
        "###########################################\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, latent_dim=4, obs_dim=2, nhidden=20):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc1 = nn.Linear(latent_dim, nhidden)\n",
        "        self.fc2 = nn.Linear(nhidden, obs_dim)\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.relu(self.fc1(z))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "###########################################\n",
        "# AUTOENCODER IMPLEMENTATION\n",
        "###########################################\n",
        "\n",
        "class LSTMAutoEncoder(TrainerModel):\n",
        "    def __init__(self, latent_dim, obs_dim, hidden_dim, device=None):\n",
        "        super(TrainerModel, self).__init__()\n",
        "        if not device:\n",
        "            self.device = 'cpu'\n",
        "        else:\n",
        "            self.device = device\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.obs_dim = obs_dim\n",
        "\n",
        "        # Model\n",
        "        self.encoder = LSTMBaseline(input_size=obs_dim,\n",
        "                                    nhidden=hidden_dim,\n",
        "                                    latent_dim=latent_dim)\n",
        "\n",
        "        self.decoder = LSTMBaseline(input_size=latent_dim,\n",
        "                                    nhidden=hidden_dim,\n",
        "                                    latent_dim=latent_dim)\n",
        "\n",
        "        self.fc1 = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, obs_dim, bias=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Loss\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encode(x)\n",
        "        pred_x = self.decode(z)\n",
        "        return pred_x\n",
        "\n",
        "    def decode(self, z):\n",
        "        x = self.decoder.forward_sequence(z, self.device)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        out = self.fc2(x)\n",
        "        return out\n",
        "\n",
        "    def encode(self, x):\n",
        "        z = self.encoder.forward_sequence(x, self.device)\n",
        "        return z\n",
        "\n",
        "    def train_step(self, x, t):\n",
        "        pred_x = self.forward(x)\n",
        "\n",
        "        # RMSE loss\n",
        "        loss = torch.sqrt(self.criterion(x, pred_x))\n",
        "        return loss\n",
        "\n",
        "    @classmethod\n",
        "    def from_checkpoint(cls, path):\n",
        "        # Usage: LSTMAutoEncoder.from_checkpoint(path)\n",
        "        obj = torch.load(path)\n",
        "        model = cls(**obj['model_args'])\n",
        "        model.encoder.load_state_dict(obj['encoder_state_dict'])\n",
        "        model.decoder.load_state_dict(obj['decoder_state_dict'])\n",
        "        model.fc1.load_state_dict(obj['fc1'])\n",
        "        model.fc2.load_state_dict(obj['fc2'])\n",
        "\n",
        "        model.train_loss = obj['train_loss']\n",
        "        model.val_loss = obj['val_loss']\n",
        "\n",
        "        return model\n",
        "\n",
        "    def get_params(self):\n",
        "        return list(self.encoder.parameters()) + list(self.decoder.parameters()) + \\\n",
        "               list(self.fc1.parameters()) + \\\n",
        "               list(self.fc2.parameters())\n",
        "\n",
        "    def get_args(self):\n",
        "        return {'latent_dim': self.latent_dim,\n",
        "                'obs_dim': self.obs_dim,\n",
        "                'hidden_dim': self.hidden_dim,\n",
        "                'device': self.device}\n",
        "\n",
        "    def get_state_dicts(self):\n",
        "        return {\n",
        "            'encoder_state_dict': self.encoder.state_dict(),\n",
        "            'decoder_state_dict': self.decoder.state_dict(),\n",
        "            'fc1': self.fc1.state_dict(),\n",
        "            'fc2': self.fc2.state_dict(),\n",
        "        }\n",
        "\n",
        "\n",
        "class ODEAutoEncoder(TrainerModel):\n",
        "    def __init__(self, data,latent_dim, obs_dim, hidden_dim, rnn_hidden_dim=None, lstm_hidden_dim=None, device=None,\n",
        "                 solver='rk4'):\n",
        "        super().__init__()\n",
        "        #super(TrainerModel, self).__init__()\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "        self.obs_dim = obs_dim\n",
        "        self.rnn_hidden_dim = rnn_hidden_dim\n",
        "        self.lstm_hidden_dim = lstm_hidden_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.solver = solver\n",
        "        self.data=data\n",
        "\n",
        "        if device is None:\n",
        "            self.device = 'cpu'\n",
        "        else:\n",
        "            self.device = device\n",
        "\n",
        "#estrae z0\n",
        "        if rnn_hidden_dim and not lstm_hidden_dim:\n",
        "            self.encoder = RecognitionRNN(latent_dim, obs_dim, rnn_hidden_dim).to(device)\n",
        "        elif lstm_hidden_dim and not rnn_hidden_dim:\n",
        "            self.encoder = LSTMEncoder(obs_dim, lstm_hidden_dim, latent_dim).to(device)\n",
        "        else:\n",
        "            raise ValueError('Please satisfy rnn_hidden_dim xor lstm_hidden_dim')\n",
        "\n",
        "        self.decoder = Decoder(latent_dim, obs_dim, hidden_dim).to(device)\n",
        "\n",
        "#risolve dz/dt=f\n",
        "        self.odefunc = LatentODEfunc(latent_dim, hidden_dim).to(device)\n",
        "        self.nfe_list = []  # Length of nfe_list is number of epochs\n",
        "\n",
        "    def check_stiffness(self, z0_sample=None, t0_sample=None):\n",
        "\n",
        "      if z0_sample is None:\n",
        "        # Usa un batch di dati dalla validation/test set\n",
        "        samp_trajs, samp_ts, *_ = self.data.get_test_data()\n",
        "        qz0_mean, qz0_logvar, epsilon = self.encode(samp_trajs)\n",
        "        z0_sample = self.sample_z0(epsilon, qz0_logvar, qz0_mean)[0]\n",
        "        t0_sample = samp_ts[0].item() if t0_sample is None else t0_sample\n",
        "\n",
        "      z0_sample = z0_sample.detach().clone().requires_grad_(True)\n",
        "\n",
        "      def f(z):\n",
        "        return self.odefunc(t0_sample, z.unsqueeze(0)).squeeze(0)\n",
        "\n",
        "      J = jacobian(f, z0_sample)\n",
        "      eigvals = torch.linalg.eigvals(J)\n",
        "      stiffness_ratio = torch.abs(eigvals).max() / (torch.abs(eigvals).min() + 1e-12)\n",
        "\n",
        "      print(f\" Stiffness ratio: {stiffness_ratio.item():.2e}\")\n",
        "      return stiffness_ratio.item()\n",
        "\n",
        "\n",
        "    def forward(self, x, t, return_z0=False):\n",
        "        # Encode\n",
        "        qz0_mean, qz0_logvar, epsilon = self.encode(x)\n",
        "\n",
        "        # Sample z0 (vector) from q(z0)\n",
        "        z0 = self.sample_z0(epsilon, qz0_logvar, qz0_mean)\n",
        "\n",
        "        # Decode\n",
        "        pred_x = self.decode(z0, t)\n",
        "\n",
        "        if return_z0:\n",
        "            return pred_x, z0\n",
        "        return pred_x\n",
        "\n",
        "#epsilon: rumore gaussiano\n",
        "    def sample_z0(self, epsilon, qz0_logvar, qz0_mean):\n",
        "        z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean\n",
        "        return z0\n",
        "\n",
        "    def encode(self, x):\n",
        "        out = self.encoder.forward_sequence(x, self.device)\n",
        "\n",
        "        # Get the q(z0) distribution (as a vector)\n",
        "        qz0_mean, qz0_logvar = out[:, :self.latent_dim], out[:, self.latent_dim:]\n",
        "        epsilon = torch.randn(qz0_mean.size()).to(self.device)\n",
        "\n",
        "        return qz0_mean, qz0_logvar, epsilon\n",
        "\n",
        "\n",
        "    def decode(self, z0, t, return_z=False):\n",
        "        # forward in time and solve ode for reconstructions\n",
        "        pred_z = odeint(self.odefunc, z0, t, method=self.solver).permute(1, 0, 2) #usa odeint derivante dal torchdiffeq\n",
        "        #pred_z=RK45(self.odefunc,t0, z0, t, max_step=inf, rtol=0.001, atol=1e-06, vectorized=False, first_step=None).permute(1,0,2)\n",
        "        pred_x = self.decoder(pred_z)\n",
        "\n",
        "        if return_z:\n",
        "            return pred_x, pred_z\n",
        "\n",
        "        return pred_x\n",
        "\n",
        "\n",
        "    def train_step(self, x, t):\n",
        "#x: samp_trajs_train oppure samp_trajs_val\n",
        "#t: samp_ts\n",
        "\n",
        "        # Encode\n",
        "        qz0_mean, qz0_logvar, epsilon = self.encode(x)\n",
        "\n",
        "        # Sample z0 (vector) from q(z0)\n",
        "        z0 = self.sample_z0(epsilon, qz0_logvar, qz0_mean)\n",
        "        #samp_ts=self.data.get_samp_ts()\n",
        "\n",
        "        # Decode\n",
        "        pred_x = self.decode(z0, t)  # potremmo forzare t ad essere pari a samp_ts\n",
        "\n",
        "\n",
        "        noise_std_ = torch.zeros(pred_x.size()).to(self.device) + .2\n",
        "        noise_logvar = 2. * torch.log(noise_std_).to(self.device)\n",
        "\n",
        "        logpx = log_normal_pdf(x, pred_x, noise_logvar).sum(-1).sum(-1)\n",
        "\n",
        "        #fixed_logvar = -5  # Fix log-variance to a very small value\n",
        "        #noise_logvar = torch.full_like(pred_x, fixed_logvar).to(self.device)\n",
        "\n",
        "        #logpx = log_normal_pdf(x, pred_x, noise_logvar).sum(-1).sum(-1)\n",
        "\n",
        "\n",
        "        pz0_mean = pz0_logvar = torch.zeros(z0.size()).to(self.device)\n",
        "\n",
        "        analytic_kl = normal_kl(qz0_mean, qz0_logvar,\n",
        "                                pz0_mean, pz0_logvar).sum(-1)\n",
        "\n",
        "        elbo = torch.mean(-logpx + analytic_kl, dim=0)\n",
        "\n",
        "        if elbo.requires_grad:\n",
        "            self.save_nfe()\n",
        "\n",
        "\n",
        "        return elbo\n",
        "\n",
        "    def save_nfe(self):\n",
        "        # save number of current forward passes\n",
        "        self.nfe_list.append(self.odefunc.nfe)\n",
        "        # Reset for next epoch\n",
        "        self.odefunc.nfe = 0\n",
        "        return\n",
        "\n",
        "    @classmethod\n",
        "    def from_checkpoint(cls, path):\n",
        "        obj = torch.load(path)\n",
        "        model = cls(**obj['model_args'])\n",
        "        model.odefunc.load_state_dict(obj['odefunc_state_dict'])\n",
        "        model.encoder.load_state_dict(obj['encoder_state_dict'])\n",
        "        model.decoder.load_state_dict(obj['decoder_state_dict'])\n",
        "\n",
        "        if 'nfe_list' in obj:\n",
        "            model.nfe_list = obj['nfe_list']\n",
        "\n",
        "        model.train_loss = obj['train_loss']\n",
        "        model.val_loss = obj['val_loss']\n",
        "\n",
        "        return model\n",
        "\n",
        "    def get_params(self):\n",
        "        return list(self.odefunc.parameters()) + list(self.decoder.parameters()) + list(self.encoder.parameters())\n",
        "\n",
        "    def get_args(self):\n",
        "        return {'latent_dim': self.latent_dim,\n",
        "                'obs_dim': self.obs_dim,\n",
        "                'hidden_dim': self.hidden_dim,\n",
        "                'rnn_hidden_dim': self.rnn_hidden_dim,\n",
        "                'lstm_hidden_dim': self.lstm_hidden_dim,\n",
        "                'device': self.device,\n",
        "                'solver': self.solver}\n",
        "\n",
        "    def get_state_dicts(self):\n",
        "        return {'odefunc_state_dict': self.odefunc.state_dict(),\n",
        "                'encoder_state_dict': self.encoder.state_dict(),\n",
        "                'decoder_state_dict': self.decoder.state_dict(),\n",
        "                'nfe_list': self.nfe_list}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n_pchB9hiWp"
      },
      "source": [
        "###Trainer class\n",
        "`train.py` class to define the training of the entire algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "elmyhlomuwRh"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, optim, data, epochs, freq, folder=None, visualizer=None):\n",
        "        assert isinstance(model, TrainerModel)\n",
        "        self.model: TrainerModel = model\n",
        "        self.optimizer = optim\n",
        "        self.data = data\n",
        "        self.epochs = epochs\n",
        "        self.freq = freq\n",
        "\n",
        "        if folder is None:\n",
        "            self.folder = 'runs/model_' + dt.now().strftime(\"%m%d_%H%M\")\n",
        "        else:\n",
        "            self.folder = folder\n",
        "\n",
        "        if visualizer is None:\n",
        "            self.visualizer = None\n",
        "        else:\n",
        "            self.visualizer = visualizer\n",
        "\n",
        "        logging.info(f'Instantiated trainer object with model {model}\\n'\n",
        "                     f'and saving in folder {self.folder}\\n'\n",
        "                     f'over {epochs} epochs logging every {freq} epoch')\n",
        "\n",
        "    @classmethod\n",
        "    def from_checkpoint(cls, model_class, path, epochs, freq, folder):\n",
        "        obj = torch.load(path)\n",
        "\n",
        "        model = model_class.from_checkpoint(path)\n",
        "        optimizer = optim.Adam(model.get_params(), lr=0)\n",
        "        optimizer.load_state_dict(obj['optimizer_state_dict'])\n",
        "\n",
        "        data = Data.from_dict(obj['data'])\n",
        "\n",
        "        visualizer = Visualizer(model, data, folder)\n",
        "\n",
        "        trainer = cls(model, optimizer, data, epochs, freq,\n",
        "                      folder=folder, visualizer=visualizer)\n",
        "\n",
        "        #logging.info(f\"Loaded model from {path}\")\n",
        "\n",
        "        # Get the version from next index where v is 'runs/model_1204_1635/ckpt/16_35_v3.pth'\n",
        "        version = 0\n",
        "        return trainer, version\n",
        "\n",
        "#viene chiamato nel main con trainer.train\n",
        "    def train(self, version=0):\n",
        "        logging.info('Inizia il training')\n",
        "\n",
        "        try:\n",
        "            for epoch in range(self.epochs):  #iterazioni per epoche\n",
        "                start = time.time()\n",
        "\n",
        "                self.train_step(*self.data.get_train_data()) #calcola ELBO e aggiorna i pesi\n",
        "                #get_train_data restituisce: samp_trajs_train, samp_ts\n",
        "                #print(\"get_train_data restituisce: \", *self.data.get_train_data())\n",
        "\n",
        "                self.validation_step(*self.data.get_val_data()) # calcola errore sulla validazione\n",
        "\n",
        "                end = time.time()\n",
        "                self.model.epoch_time.append(end - start)\n",
        "\n",
        "                if epoch % self.freq == 0: #ogni tot epoche\n",
        "                    if isinstance(self.model, ODEAutoEncoder):\n",
        "                        logging.info(f'Current number of forward passes: {self.model.nfe_list[-1]}')\n",
        "\n",
        "                    logging.info('Epoch: {}, train elbo: {:.4f}, validation elbo: {:.4f}, mean time per epoch: {:.4f}'\n",
        "                                 .format(epoch,\n",
        "                                         self.model.train_loss[-1],\n",
        "                                         self.model.val_loss[-1],\n",
        "                                         np.mean(self.model.epoch_time)))\n",
        "                    print(\"Salviamo il modello\")\n",
        "                    self.save_model(version)\n",
        "                    print(\"Chiamiamo lo step di visualizzazione\")\n",
        "                    self.visualize_step(version)\n",
        "                    version += 1\n",
        "\n",
        "#logging e visualizzazione dei risultati alla fine di tutto il ciclo for\n",
        "            logging.info(f'Training finished after {epoch} epochs')\n",
        "            self.save_model('final')\n",
        "            print(\"Visualizzazione finale\")\n",
        "            self.visualize_final()\n",
        "\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            logging.info('Stopped training due to interruption')\n",
        "            self.save_model(version)\n",
        "            self.visualize_final('interrupted')\n",
        "\n",
        "    def visualize_step(self, version):\n",
        "        if self.visualizer:\n",
        "            self.visualizer.visualize_step(version)\n",
        "\n",
        "    def visualize_final(self, version='final'):\n",
        "        if self.visualizer:\n",
        "            self.visualizer.visualize_final(version)\n",
        "\n",
        "#viene chiamata in train con input samp_trajs_train, samp_ts oppure samp_trajs_val, samp_ts\n",
        "    def train_step(self, x, t):\n",
        "\n",
        "        self.model.train() #attiva il modello in modalità training\n",
        "\n",
        "        self.optimizer.zero_grad() #azzera i gradienti dell'ottimizzatore\n",
        "\n",
        "        # Perform train step\n",
        "        elbo = self.model.train_step(x, t)\n",
        "\n",
        "        # Backwards pass and update optimizer and train loss\n",
        "        elbo.backward() #calcola il gradiente della loss rispetto ai pesi del modello usando il backpropagation\n",
        "        self.optimizer.step() #aggiorna i pesi del modello utilizzando l'ottimizzatore\n",
        "        self.model.train_loss.append(-elbo.item()) #salva la loss nella lista train_loss del modello\n",
        "\n",
        "\n",
        "    def validation_step(self, x, t):\n",
        "      self.model.eval()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        # Compute the ELBO for the current validation step\n",
        "        elbo = self.model.train_step(x, t)\n",
        "        self.model.val_loss.append(-elbo.item())\n",
        "\n",
        "    def save_model(self, version):\n",
        "        folder = os.path.join(self.folder, 'ckpt')\n",
        "\n",
        "        now = dt.now().strftime('%H_%M')\n",
        "        ckpt_path = os.path.join(folder, f'{now}_v{version}.pth')\n",
        "#\n",
        "        save_dict = {\n",
        "            'model_args': self.model.get_args(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'data': self.data.get_dict(),\n",
        "            'train_loss': self.model.train_loss,\n",
        "            'val_loss': self.model.val_loss\n",
        "        }\n",
        "        save_dict.update(self.model.get_state_dicts())\n",
        "        torch.save(save_dict, ckpt_path)\n",
        "\n",
        "        logging.info(f\"Saved model at {ckpt_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RKkAHzSAC49T"
      },
      "outputs": [],
      "source": [
        "def setup_folders(folder):\n",
        "    if not os.path.exists(folder + 'png'): #controlla se la cartella folder+'png' esiste\n",
        "        #logging.info(f\"{folder + 'png'} does not exist... creating\")\n",
        "        os.makedirs(folder + 'png') #crea la directory nel percorso\n",
        "\n",
        "    if not os.path.exists(folder + 'ckpt'):\n",
        "        #logging.info(f\"{folder + 'ckpt'} does not exist... creating\")\n",
        "\n",
        "        os.makedirs(folder + 'ckpt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTScbtSP_uOU"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pr7R62g8Lcv"
      },
      "source": [
        "### Load of EEG dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9XfjlyrvF_Oy"
      },
      "outputs": [],
      "source": [
        "def load_eeg_data(file_path, file_type='edf', mat_key='eeg_matrix', subject='unknown', condition='unknown'):\n",
        "    \"\"\"\n",
        "    Carica EEG da file .edf o .mat e restituisce un dizionario con metadati nella chiave.\n",
        "\n",
        "    Returns:\n",
        "        dict con chiave formattata, sampling_rate, channel_names, times\n",
        "    \"\"\"\n",
        "    if file_type == 'edf':\n",
        "        raw = mne.io.read_raw_edf(file_path, preload=True, verbose=False)\n",
        "        eeg_data, times = raw.get_data(return_times=True)\n",
        "        sampling_rate = raw.info['sfreq']\n",
        "        channel_names = raw.ch_names\n",
        "\n",
        "    elif file_type == 'mat':\n",
        "        mat_data = scipy.io.loadmat(file_path)\n",
        "        if mat_key not in mat_data:\n",
        "            raise KeyError(f\"'{mat_key}' not found in .mat file.\")\n",
        "        eeg_data = mat_data[mat_key]\n",
        "        times = None\n",
        "        sampling_rate = 250\n",
        "        num_channels = eeg_data.shape[0]\n",
        "        channel_names = [f\"E{i+1}\" for i in range(num_channels)]\n",
        "    else:\n",
        "        raise ValueError(\"file_type must be either 'edf' or 'mat'.\")\n",
        "\n",
        "    # Crea chiave identificativa\n",
        "    key = f\"{subject}_{condition}_{file_type}\"\n",
        "\n",
        "    # Ritorna tutto in un dizionario\n",
        "    return {\n",
        "        key: eeg_data,\n",
        "        'sampling_rate': sampling_rate,\n",
        "        'channel_names': channel_names,\n",
        "        'times': times\n",
        "    }\n",
        "\n",
        "\n",
        "def load_and_plot_channel_locations(loc_file_path, show_labels=True, title=\"Scalp EEG Channel Locations\"):\n",
        "    \"\"\"\n",
        "    Carica e plotta le posizioni dei canali EEG da un file .loc (formato GSN_Hydrocel).\n",
        "\n",
        "    Args:\n",
        "        loc_file_path (str): path del file .loc\n",
        "        show_labels (bool): se True mostra le etichette dei canali\n",
        "        title (str): titolo del grafico\n",
        "\n",
        "    Returns:\n",
        "        loc_df: DataFrame con le coordinate e i label dei canali\n",
        "    \"\"\"\n",
        "    loc_df = pd.read_csv(loc_file_path, sep='\\s+', header=None)\n",
        "    loc_df.columns = ['Index', 'Theta', 'Radius', 'Label']\n",
        "\n",
        "    # Conversione da coordinate polari a cartesiane\n",
        "    loc_df['Theta_rad'] = np.deg2rad(loc_df['Theta'])\n",
        "    loc_df['X'] = loc_df['Radius'] * np.cos(loc_df['Theta_rad'])\n",
        "    loc_df['Y'] = loc_df['Radius'] * np.sin(loc_df['Theta_rad'])\n",
        "\n",
        "    %matplotlib inline\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.scatter(loc_df['X'], loc_df['Y'], s=80, c='skyblue', edgecolor='k')\n",
        "\n",
        "    if show_labels:\n",
        "        for _, row in loc_df.iterrows():\n",
        "            plt.text(row['X'] + 0.005, row['Y'] + 0.005, row['Label'], fontsize=7)\n",
        "\n",
        "    # Cerchio per simulare lo scalpo\n",
        "    scalp = plt.Circle((0, 0), max(loc_df['Radius']), color='k', fill=False, linestyle='--')\n",
        "    plt.gca().add_artist(scalp)\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.axis('equal')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return loc_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT42V9DXbN1_"
      },
      "source": [
        "###Importing .mat file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WIbWDRz1IA2k"
      },
      "outputs": [],
      "source": [
        "subject = '001'\n",
        "condition = 'baseline'\n",
        "file_type = 'mat'\n",
        "\n",
        "result = load_eeg_data(\n",
        "    file_path=f'./Dataset/SUB{subject}/SUB{subject}_eeg_{condition}.mat',\n",
        "    file_type=file_type,\n",
        "    subject=subject,\n",
        "    condition=condition\n",
        ")\n",
        "\n",
        "# Accesso ai dati\n",
        "key = f\"{subject}_{condition}_{file_type}\"\n",
        "eeg_data = result[key]\n",
        "sampling_rate = result['sampling_rate']\n",
        "channel_names = result['channel_names']\n",
        "times = result['times']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omOWitBCKzBu"
      },
      "source": [
        "###Channels location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "QYcVWnIcIN2U",
        "outputId": "3ba0aa43-affb-4529-850a-d04026d71939"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "loc_file = './GSN_Hydrocel_64.loc'\n",
        "channel_locs_df = load_and_plot_channel_locations(loc_file, show_labels=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbBkhQ9p8S71"
      },
      "source": [
        "###FIR/IIR filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I6Ub54sU995C"
      },
      "outputs": [],
      "source": [
        "def fir_filter_eeg_data_vaeeeg(eeg_data, fs, bands=None,\n",
        "                                fir_design='firwin', l_trans=0.1, h_trans=0.1, phase='zero'):\n",
        "    \"\"\"\n",
        "    Applica filtraggio FIR stile VAEEG all'intero segnale EEG per ciascuna banda.\n",
        "\n",
        "    Args:\n",
        "        eeg_data (np.ndarray): EEG (n_channels x n_samples)\n",
        "        fs (int): Frequenza di campionamento\n",
        "        bands (dict): Dizionario bande {'Alpha': (8, 13), ...}\n",
        "        fir_design (str): Tipo di FIR (default 'firwin')\n",
        "        l_trans (float): Banda di transizione bassa (Hz)\n",
        "        h_trans (float): Banda di transizione alta (Hz)\n",
        "        phase (str): Tipo di fase ('zero' o 'minimum')\n",
        "\n",
        "    Returns:\n",
        "        dict: {banda: {ch_idx: segnale filtrato (shape = n_samples)}}\n",
        "    \"\"\"\n",
        "    if bands is None:\n",
        "        bands = {\n",
        "            'Delta': (0.5, 4),\n",
        "            'Theta': (4, 8),\n",
        "            'Alpha': (8, 13),\n",
        "            'Low_beta': (13, 20),\n",
        "            'High_beta': (20, 30)\n",
        "        }\n",
        "\n",
        "    n_channels, n_samples = eeg_data.shape\n",
        "\n",
        "    # Forza float64 per compatibilità MNE\n",
        "    eeg_data = eeg_data.astype(np.float64)\n",
        "\n",
        "    # Inizializza dizionario output\n",
        "    filtered_data = {\n",
        "        band: {} for band in bands\n",
        "    }\n",
        "\n",
        "    for ch_idx in range(n_channels):\n",
        "        ch_signal = eeg_data[ch_idx]\n",
        "\n",
        "        for band, (lowcut, highcut) in bands.items():\n",
        "            try:\n",
        "                filtered_signal = filter_data(\n",
        "                    ch_signal,\n",
        "                    sfreq=fs,\n",
        "                    l_freq=lowcut,\n",
        "                    h_freq=highcut,\n",
        "                    method='fir',\n",
        "                    fir_design=fir_design,\n",
        "                    l_trans_bandwidth=l_trans,\n",
        "                    h_trans_bandwidth=h_trans,\n",
        "                    phase=phase,\n",
        "                    verbose=False\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"Errore filtrando canale {ch_idx}, banda {band}: {e}\")\n",
        "                filtered_signal = np.zeros_like(ch_signal)\n",
        "\n",
        "            filtered_data[band][ch_idx] = filtered_signal\n",
        "\n",
        "    return filtered_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gplxiEy-ANV",
        "outputId": "3fe04363-3ee8-4d05-88ea-d1e8389fa41b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FIR filtering took 7.0130 seconds.\n"
          ]
        }
      ],
      "source": [
        "fs = 250\n",
        "start_time = time.time()\n",
        "\n",
        "filtered = fir_filter_eeg_data_vaeeeg(eeg_data, fs)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(f\"FIR filtering took {elapsed_time:.4f} seconds.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKUKD-5tkPZP"
      },
      "source": [
        "###Dataset splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kJYMa2xo9SOR"
      },
      "outputs": [],
      "source": [
        "def window_eeg_data(\n",
        "    filtered_data,\n",
        "    window_size,\n",
        "    overlap,\n",
        "    subject,\n",
        "    condition,\n",
        "    output_dir=\"/content/drive/MyDrive/Tesi/windows\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Suddivide i segnali EEG filtrati in finestre sovrapposte e salva ogni finestra per canale e banda.\n",
        "\n",
        "    Args:\n",
        "        filtered_data (dict): struttura {banda: {channel_number: segnale}}\n",
        "        window_size (int): numero di campioni per finestra\n",
        "        overlap (int): sovrapposizione tra finestre (in campioni)\n",
        "        subject (str): identificativo soggetto\n",
        "        condition (str): condizione (es. baseline, vr1...)\n",
        "        output_dir (str): directory base dove salvare le finestre\n",
        "    \"\"\"\n",
        "    step_size = window_size - overlap\n",
        "    eeg_channel_indices = max([\n",
        "        max(filtered_data[band].keys()) for band in filtered_data\n",
        "    ])\n",
        "    print(f\"Numero di canali EEG validi: {eeg_channel_indices}\")\n",
        "\n",
        "    for ch_idx in range(eeg_channel_indices):\n",
        "        channel_num = ch_idx + 1  # 1-based indexing\n",
        "\n",
        "        for band in filtered_data.keys():\n",
        "            if channel_num not in filtered_data[band]:\n",
        "                print(f\"Canale mancante: {channel_num} nella banda {band}. Salto...\")\n",
        "                continue\n",
        "\n",
        "            signal = filtered_data[band][channel_num]\n",
        "            n = len(signal)\n",
        "            n_windows = (n - overlap) // step_size\n",
        "            eeg_windows = np.zeros((n_windows, window_size, 2))\n",
        "\n",
        "            for i in range(n_windows):\n",
        "                start_idx = i * step_size\n",
        "                end_idx = start_idx + window_size\n",
        "                eeg_windows[i, :, 0] = np.arange(1, window_size + 1)\n",
        "                eeg_windows[i, :, 1] = signal[start_idx:end_idx]\n",
        "\n",
        "            # Salvataggio\n",
        "            save_path = f\"{output_dir}/windowsize{window_size}/overlap{overlap}/SUB{subject}/condition{condition}/eeg_{band}_channel_{channel_num}_windows.npy\"\n",
        "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "            np.save(save_path, eeg_windows)\n",
        "            print(f\"Salvato: {save_path}\")\n",
        "\n",
        "    print(f\"Total number of windows for each channel and each band: {n_windows}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TItKa6qcAeVw",
        "outputId": "a5f9e8ee-cc08-4f71-85c1-d50c00417b52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numero di canali EEG validi: 64\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_1_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_1_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_1_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_1_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_1_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_2_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_2_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_2_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_2_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_2_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_3_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_3_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_3_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_3_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_3_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_4_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_4_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_4_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_4_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_4_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_5_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_5_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_5_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_5_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_5_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_6_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_6_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_6_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_6_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_6_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_7_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_7_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_7_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_7_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_7_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_8_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_8_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_8_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_8_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_8_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_9_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_9_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_9_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_9_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_9_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_10_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_10_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_10_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_10_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_10_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_11_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_11_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_11_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_11_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_11_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_12_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_12_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_12_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_12_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_12_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_13_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_13_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_13_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_13_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_13_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_14_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_14_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_14_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_14_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_14_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_15_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_15_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_15_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_15_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_15_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_16_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_16_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_16_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_16_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_16_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_17_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_17_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_17_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_17_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_17_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_18_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_18_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_18_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_18_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_18_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_19_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_19_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_19_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_19_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_19_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_20_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_20_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_20_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_20_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_20_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_21_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_21_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_21_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_21_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_21_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_22_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_22_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_22_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_22_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_22_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_23_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_23_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_23_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_23_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_23_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_24_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_24_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_24_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_24_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_24_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_25_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_25_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_25_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_25_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_25_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_26_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_26_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_26_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_26_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_26_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_27_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_27_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_27_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_27_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_27_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_28_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_28_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_28_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_28_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_28_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_29_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_29_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_29_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_29_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_29_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_30_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_30_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_30_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_30_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_30_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_31_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_31_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_31_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_31_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_31_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_32_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_32_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_32_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_32_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_32_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_33_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_33_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_33_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_33_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_33_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_34_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_34_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_34_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_34_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_34_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_35_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_35_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_35_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_35_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_35_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_36_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_36_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_36_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_36_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_36_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_37_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_37_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_37_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_37_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_37_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_38_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_38_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_38_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_38_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_38_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_39_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_39_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_39_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_39_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_39_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_40_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_40_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_40_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_40_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_40_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_41_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_41_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_41_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_41_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_41_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_42_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_42_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_42_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_42_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_42_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_43_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_43_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_43_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_43_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_43_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_44_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_44_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_44_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_44_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_44_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_45_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_45_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_45_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_45_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_45_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_46_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_46_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_46_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_46_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_46_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_47_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_47_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_47_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_47_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_47_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_48_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_48_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_48_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_48_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_48_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_49_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_49_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_49_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_49_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_49_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_50_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_50_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_50_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_50_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_50_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_51_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_51_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_51_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_51_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_51_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_52_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_52_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_52_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_52_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_52_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_53_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_53_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_53_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_53_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_53_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_54_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_54_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_54_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_54_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_54_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_55_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_55_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_55_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_55_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_55_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_56_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_56_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_56_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_56_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_56_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_57_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_57_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_57_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_57_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_57_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_58_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_58_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_58_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_58_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_58_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_59_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_59_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_59_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_59_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_59_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_60_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_60_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_60_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_60_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_60_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_61_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_61_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_61_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_61_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_61_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_62_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_62_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_62_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_62_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_62_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_63_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_63_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_63_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_63_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_63_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Delta_channel_64_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Theta_channel_64_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Alpha_channel_64_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_Low_beta_channel_64_windows.npy\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize250/overlap63/SUB001/conditionbaseline/eeg_High_beta_channel_64_windows.npy\n",
            "Total number of windows for each channel and each band: 78\n"
          ]
        }
      ],
      "source": [
        "window_size=250\n",
        "window_eeg_data(\n",
        "    filtered_data=filtered,\n",
        "    window_size=window_size,\n",
        "    overlap=63,\n",
        "    subject='001',\n",
        "    condition='baseline',\n",
        "    output_dir=\"./windows\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWkbjksH2z-y"
      },
      "source": [
        "###Combined channels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "l2yNeSQYiWLO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def window_eeg_concat_channels(\n",
        "    filtered_data,\n",
        "    window_size,\n",
        "    overlap,\n",
        "    subject,\n",
        "    condition,\n",
        "    channel_list,\n",
        "    output_dir=\"./windows\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Crea finestre sovrapposte su ciascun canale EEG e concatena tutte le finestre\n",
        "    in un unico array, salvato per ogni banda.\n",
        "\n",
        "    Args:\n",
        "        filtered_data (dict): {banda: {channel_number: segnale 1D}}\n",
        "        window_size (int): lunghezza di ogni finestra (in campioni)\n",
        "        overlap (int): sovrapposizione tra finestre (in campioni)\n",
        "        subject (str): es. '001'\n",
        "        condition (str): es. 'baseline'\n",
        "        channel_list (list): lista dei canali da includere\n",
        "        output_dir (str): directory base per il salvataggio\n",
        "    \"\"\"\n",
        "    step_size = window_size - overlap\n",
        "    total_windows_per_band = {}\n",
        "\n",
        "    for band in filtered_data.keys():\n",
        "        all_windows = []\n",
        "\n",
        "        for ch in channel_list:\n",
        "            if ch not in filtered_data[band]:\n",
        "                print(f\"Missing channel {ch} in band {band}, skipping...\")\n",
        "                continue\n",
        "\n",
        "            signal = filtered_data[band][ch]\n",
        "            T = len(signal)\n",
        "            n_windows = (T - overlap) // step_size\n",
        "\n",
        "            for i in range(n_windows):\n",
        "                start_idx = i * step_size\n",
        "                end_idx = start_idx + window_size\n",
        "                if end_idx > T:\n",
        "                    break\n",
        "\n",
        "                window = np.zeros((window_size, 2))  # (time, signal)\n",
        "                window[:, 0] = np.arange(1, window_size + 1)\n",
        "                window[:, 1] = signal[start_idx:end_idx]\n",
        "                all_windows.append(window)\n",
        "\n",
        "        all_windows = np.stack(all_windows, axis=0)  # shape: (n_windows_total, window_size, 2)\n",
        "        total_windows_per_band[band] = all_windows.shape[0]\n",
        "\n",
        "        ch_str = \"_\".join(str(c) for c in channel_list)\n",
        "        save_path = f\"{output_dir}/windowsize{window_size}/SUB{subject}/condition{condition}/eeg_{band}_channels_{ch_str}_windows.npy\"\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "        np.save(save_path, all_windows)\n",
        "\n",
        "        print(f\"Salvato: {save_path} con shape {all_windows.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fdVahQNdwkQ",
        "outputId": "f38ea730-5f58-4844-e513-18178302de2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize40/SUB001/conditionbaseline/eeg_Delta_channels_33_34_35_windows.npy con shape (2208, 40, 2)\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize40/SUB001/conditionbaseline/eeg_Theta_channels_33_34_35_windows.npy con shape (2208, 40, 2)\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize40/SUB001/conditionbaseline/eeg_Alpha_channels_33_34_35_windows.npy con shape (2208, 40, 2)\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize40/SUB001/conditionbaseline/eeg_Low_beta_channels_33_34_35_windows.npy con shape (2208, 40, 2)\n",
            "Salvato: /content/drive/MyDrive/Tesi/windows/windowsize40/SUB001/conditionbaseline/eeg_High_beta_channels_33_34_35_windows.npy con shape (2208, 40, 2)\n"
          ]
        }
      ],
      "source": [
        "channel_list=[33, 34, 35]\n",
        "combined_channels=len(channel_list)\n",
        "window_eeg_concat_channels(\n",
        "    filtered_data=filtered,\n",
        "    window_size=40,\n",
        "    overlap=20,\n",
        "    subject='001',\n",
        "    condition='baseline',\n",
        "    channel_list=[33, 34, 35]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rud1cnJCZJ6"
      },
      "source": [
        "### Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Aqlio88as22j"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    if combined_channels==1:\n",
        "      save_path = f\"./windows/windowsize{window_size}/overlap{overlap}/SUB{subject}/condition{condition}/eeg_{band}_channel_{channel}_windows.npy\"\n",
        "    if combined_channels==3:\n",
        "      save_path=f\"./windows/windowsize{window_size}/SUB{subject}/condition{condition}/eeg_{band}_channels_{channel}_{channel+1}_{channel+2}_windows.npy\"\n",
        "    if combined_channels==7:\n",
        "      save_path=f\"/./windows/windowsize{window_size}/SUB{subject}/condition{condition}/eeg_{band}_channels_{channel}_{channel+1}_{channel+2}_{channel+3}_{channel+4}_{channel+5}_{channel+6}_windows.npy\"\n",
        "\n",
        "    data = np.load(save_path) #carica il file\n",
        "    #data = np.load(f\"./eeg_{band}_channel_{channel}_windows.npy\")\n",
        "    #print(\"Forma di eeg_windows: \",data.shape)\n",
        "    n = data.shape[1] #window_size\n",
        "\n",
        "    #creazione delle finestre temporali\n",
        "    start = 1\n",
        "    stop = window_size\n",
        "\n",
        "    start_idx = int(n * 0.00)\n",
        "    stop_idx = int(n * 1)\n",
        "\n",
        "    #def dell'intervallo temporale\n",
        "    orig_ts = np.linspace(start, stop, num=n) #generazione della sequenza temporale da 0 a window_size con n valori equidistanti\n",
        "    #print(\"orig_ts: \",orig_ts)\n",
        "    #orig_ts = (orig_ts - orig_ts.min()) / (orig_ts.max() - orig_ts.min())  # Normalizzazione 0-1\n",
        "\n",
        "    #def dell'intervallo di campionamento\n",
        "    samp_ts = orig_ts[start_idx:stop_idx] #selezione delle finestre temporali (dal 5% al 90% del dataset)\n",
        "    #estrazione di una sotto-sequenza temporale\n",
        "    #print(\"samp_ts: \",samp_ts)\n",
        "\n",
        "    #normalizzazione delle traiettorie\n",
        "    orig_trajs = [] #lista per memorizzare tutte le traiettorie normalizzate\n",
        "    samp_trajs = [] #lista per memorizzare tutte le traiettorie dopo la selezione della finestra temporale\n",
        "    #print(\"Numero totale di traiettorie: \", data.shape[0])\n",
        "    for trajs in data: #per ogni finestra trajs presente in data\n",
        "        #orig_traj = (trajs - trajs.mean()) / trajs.std() #normalizzazione--> media 0 e varianza 1\n",
        "        #orig_traj = (trajs - trajs.min()) / (trajs.max() - trajs.min())\n",
        "        orig_traj=trajs\n",
        "        samp_traj = orig_traj[start_idx:stop_idx] #selezione solo la porzione di interesse\n",
        "\n",
        "        #salvataggio nei rispettivi array\n",
        "        orig_trajs.append(orig_traj)\n",
        "        samp_trajs.append(samp_traj)\n",
        "\n",
        "    orig_trajs = np.stack(orig_trajs, axis=0) #conversione in tensori PyTorch\n",
        "    samp_trajs = np.stack(samp_trajs, axis=0)\n",
        "\n",
        "    #in questo modo ci assicuriamo che i dati siano tutti nello stesso device, trasferimento su GPU se possibile\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    orig_trajs = torch.tensor(orig_trajs, dtype=torch.float32).to(device)\n",
        "    samp_trajs = torch.tensor(samp_trajs, dtype=torch.float32).to(device)\n",
        "    orig_ts = torch.tensor(orig_ts, dtype=torch.float32).to(device)\n",
        "    samp_ts = torch.tensor(samp_ts, dtype=torch.float32).to(device)\n",
        "\n",
        "    #print(\"shape orig_trajs:\", orig_trajs.shape)\n",
        "    #print(\"shape samp_trajs: \", samp_trajs.shape)\n",
        "    #print(\"shape orig_ts:\",  orig_ts.shape)\n",
        "    #print(\"shape samp_ts:\",samp_ts.shape)\n",
        "\n",
        "    #plot_trajectories(orig_trajs, orig_ts, samp_trajs, samp_ts)\n",
        "\n",
        "    return orig_trajs, samp_trajs, orig_ts, samp_ts\n",
        "\n",
        "    #OUTPUT\n",
        "    #orig_trajs: Traiettorie EEG normalizzate\n",
        "    #samp_trajs:  Sottoinsieme delle traiettorie selezionate\n",
        "    #orig_ts: Sequenza temporale completa.\n",
        "    #samp_ts: Sottoinsieme della sequenza temporale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJoP2cc3Hm56"
      },
      "source": [
        "###Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cnRgJhNDHpvG"
      },
      "outputs": [],
      "source": [
        "def cleanup_after_band_channel(band, channel):\n",
        "    \"\"\"\n",
        "    Pulisce memoria, GPU, figure e file temporanei per banda e canale specifici.\n",
        "\n",
        "\n",
        "    Args:\n",
        "        band (str): Nome della banda (es. 'Alpha', 'Gamma', ecc.)\n",
        "        channel (int): Numero del canale (1-based)\n",
        "        save_dir (str): Directory dove salvi metriche, ricostruzioni, ecc.\n",
        "    \"\"\"\n",
        "\n",
        "    # Pulizia variabili intermedie (se esistono)\n",
        "    for var_name in ['pred_x_rec', 'pred_x_pos', 'pred_x_neg',\n",
        "                     'qz0_mean', 'qz0_logvar', 'epsilon', 'z0']:\n",
        "        if var_name in globals():\n",
        "            del globals()[var_name]\n",
        "\n",
        "    # Garbage collection + GPU cache\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Pulizia matplotlib\n",
        "    #plt.close('all')\n",
        "\n",
        "    print(f\"[✔] Pulizia completata per banda '{band}', canale {channel}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ar_BdmEu6DX"
      },
      "source": [
        "### Main of the training\n",
        "`main.py`\\\n",
        "To decide:\n",
        "\n",
        "\n",
        "*   hyperparameters\n",
        "*   which model to use\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YKCorYip2usa"
      },
      "outputs": [],
      "source": [
        "def reconstruct_from_windows(windows, window_size, overlap_steps, value_col=1):\n",
        "    \"\"\"\n",
        "    Ricostruisce un segnale completo dalle finestre con passo fisso in campioni.\n",
        "\n",
        "    Args:\n",
        "        windows (np.ndarray): Array delle finestre (n_windows, window_size, n_features) o (n_windows, window_size)\n",
        "        window_size (int): Dimensione della finestra in campioni\n",
        "        overlap_steps (int): Numero di campioni di overlap tra finestre\n",
        "        value_col (int): Colonna da considerare in caso di finestre multicanale\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Segnale ricostruito\n",
        "    \"\"\"\n",
        "    assert 0 <= overlap_steps < window_size, \"Overlap must be in the range [0, window_size)\"\n",
        "\n",
        "    # Calcola lo step tra finestre\n",
        "    step_size = window_size - overlap_steps\n",
        "    total_length = step_size * (windows.shape[0] - 1) + window_size\n",
        "\n",
        "    # Prealloca i vettori per il segnale ricostruito e i contatori\n",
        "    signal = np.zeros(total_length)\n",
        "    counts = np.zeros(total_length)\n",
        "\n",
        "    # Ricostruzione del segnale\n",
        "    for i, window in enumerate(windows):\n",
        "        start = i * step_size\n",
        "        end = start + window_size\n",
        "\n",
        "        # Supporta finestre sia (window_size,) che (window_size, n_features)\n",
        "        if window.ndim == 1:\n",
        "            signal[start:end] += window\n",
        "        else:\n",
        "            signal[start:end] += window[:, value_col]\n",
        "\n",
        "        counts[start:end] += 1\n",
        "\n",
        "    # Evita divisione per zero\n",
        "    counts[counts == 0] = 1\n",
        "    return signal / counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gCabwxQMtadL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "def compute_val_metrics(base_path, window_size, overlap_steps, subject, condition, band, channel, combined_channels=1):\n",
        "    \"\"\"\n",
        "    Calcola RMSE e Pearson correlation sul validation set (20% dopo il 60% del segnale) e salva il plot del validation set.\n",
        "\n",
        "    Args:\n",
        "        base_path (str): Directory principale.\n",
        "        window_size (int): Dimensione della finestra in campioni.\n",
        "        overlap_steps (int): Numero di campioni di overlap tra finestre.\n",
        "        subject (str): ID del soggetto (es. \"001\").\n",
        "        condition (str): Condizione (es. \"baseline\").\n",
        "        band (str): Banda (es. \"Alpha\").\n",
        "        channel (int): Numero del canale.\n",
        "        combined_channels (int): Numero di canali combinati (1, 3 o 7).\n",
        "\n",
        "    Returns:\n",
        "        tuple: (RMSE, Pearson correlation)\n",
        "    \"\"\"\n",
        "    # Percorsi ai file\n",
        "    if combined_channels == 1:\n",
        "        rec_path = f\"{base_path}/Reconstructions/windowsize{window_size}/overlap{overlap_steps}/SUB{subject}/condition{condition}/band{band}/channel{channel}/final_reconstruction.npy\"\n",
        "        orig_path = f\"{base_path}/windows/windowsize{window_size}/overlap{overlap_steps}/SUB{subject}/condition{condition}/eeg_{band}_channel_{channel}_windows.npy\"\n",
        "        plot_dir = f\"{base_path}/Reconstructions/windowsize{window_size}/overlap{overlap_steps}/SUB{subject}/condition{condition}/band{band}/channel{channel}\"\n",
        "    elif combined_channels == 3:\n",
        "        rec_path = f\"{base_path}/Reconstructions/windowsize{window_size}/overlap{overlap_steps}/SUB{subject}/condition{condition}/band{band}/channels_{channel}_{channel+1}_{channel+2}/final_reconstruction.npy\"\n",
        "        orig_path = f\"{base_path}/windows/windowsize{window_size}/SUB{subject}/condition{condition}/eeg_{band}_channels_{channel}_{channel+1}_{channel+2}_windows.npy\"\n",
        "        plot_dir = f\"{base_path}/Reconstructions/windowsize{window_size}/overlap{overlap_steps}/SUB{subject}/condition{condition}/band{band}/channels_{channel}_{channel+1}_{channel+2}\"\n",
        "    elif combined_channels == 7:\n",
        "        rec_path = f\"{base_path}/Reconstructions/windowsize{window_size}/overlap{overlap_steps}/SUB{subject}/condition{condition}/band{band}/channels_{channel}_{channel+1}_{channel+2}_{channel+3}_{channel+4}_{channel+5}_{channel+6}/final_reconstruction.npy\"\n",
        "        orig_path = f\"{base_path}/windows/windowsize{window_size}/SUB{subject}/condition{condition}/eeg_{band}_channels_{channel}_{channel+1}_{channel+2}_{channel+3}_{channel+4}_{channel+5}_{channel+6}_windows.npy\"\n",
        "        plot_dir = f\"{base_path}/Reconstructions/windowsize{window_size}/overlap{overlap_steps}/SUB{subject}/condition{condition}/band{band}/channels_{channel}_{channel+1}_{channel+2}_{channel+3}_{channel+4}_{channel+5}_{channel+6}\"\n",
        "    else:\n",
        "        raise ValueError(\"Invalid number of combined_channels. Use 1, 3, or 7.\")\n",
        "\n",
        "    # Creazione directory per salvare il plot\n",
        "    os.makedirs(plot_dir, exist_ok=True)\n",
        "\n",
        "    # Caricamento finestre\n",
        "    windows_rec = np.load(rec_path)\n",
        "    windows_orig = np.load(orig_path)\n",
        "\n",
        "    # Ricostruzione segnali completi\n",
        "    reconstructed_signal = reconstruct_from_windows(windows_rec, window_size, overlap_steps=overlap_steps, value_col=1)\n",
        "    original_signal = reconstruct_from_windows(windows_orig, window_size, overlap_steps=overlap_steps, value_col=1)\n",
        "\n",
        "    # Definizione degli indici per il validation set\n",
        "    total_len = len(original_signal)\n",
        "    val_start = int(total_len * 0.6)\n",
        "    val_end = int(total_len * 0.8)\n",
        "\n",
        "    # Estrazione del validation set\n",
        "    original_val = original_signal[val_start:val_end]\n",
        "    reconstructed_val = reconstructed_signal[val_start:val_end]\n",
        "\n",
        "    # Calcolo RMSE\n",
        "    rmse = np.sqrt(np.mean((original_val - reconstructed_val) ** 2))\n",
        "\n",
        "    # Calcolo Pearson\n",
        "    pearson_corr, _ = pearsonr(original_val, reconstructed_val)\n",
        "\n",
        "    # Salvataggio del plot\n",
        "    plot_path = os.path.join(plot_dir, \"validation_plot.png\")\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.plot(original_val, label=\"Original (Validation)\", alpha=0.7)\n",
        "    plt.plot(reconstructed_val, label=\"Reconstructed (Validation)\", alpha=0.7)\n",
        "    plt.title(f\"Validation Set (Window Size: {window_size}, Overlap: {overlap_steps})\\nRMSE: {rmse:.6f}, Pearson Corr: {pearson_corr:.6f}\")\n",
        "    plt.xlabel(\"Samples\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "    plt.legend()\n",
        "    plt.savefig(plot_path)\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"RMSE: {rmse:.6f}, Pearson Correlation: {pearson_corr:.6f} for window_size: {window_size} and overlap: {overlap_steps}\")\n",
        "    print(f\"Validation plot saved to: {plot_path}\")\n",
        "\n",
        "    return rmse, pearson_corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t_SrrNIwoRL",
        "outputId": "75ac554d-29f5-44f2-e9e6-4aaea6fa7eed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-17 11:42:38,751 - INFO - Production run\n",
            "2025-05-17 11:42:38,792 - WARNING - Inputs cannot be converted to torch (already a torch obj?)\n",
            "Types of orig_trajs, samp_trajs, orig_ts, samp_ts: (<class 'torch.Tensor'>, <class 'torch.Tensor'>, <class 'torch.Tensor'>, <class 'torch.Tensor'>) \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Canale:  33\n",
            "Sto processando la banda: Alpha\n",
            "Logging salvato in: /content/drive/MyDrive/Tesi/Alpha/33/runs/eeg_model_0517_1142_38/logs_0517_1142_38.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-17 11:42:38,925 - INFO - Instantiated trainer object with model ODEAutoEncoder(\n",
            "  (encoder): LSTMEncoder(\n",
            "    (lstm): LSTMCell(2, 64)\n",
            "    (h2o): Linear(in_features=64, out_features=128, bias=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
            "  )\n",
            "  (odefunc): LatentODEfunc(\n",
            "    (elu): ELU(alpha=1.0, inplace=True)\n",
            "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
            "  )\n",
            ")\n",
            "and saving in folder /content/drive/MyDrive/Tesi/Alpha/33/runs/eeg_model_0517_1142_38/\n",
            "over 400 epochs logging every 100 epoch\n",
            "2025-05-17 11:42:38,927 - INFO - Inizia il training\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Stiffness ratio: 5.94e+03\n",
            "Il sistema è probabilmente stiff.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-17 11:42:39,290 - INFO - Current number of forward passes: 1\n",
            "2025-05-17 11:42:39,299 - INFO - Epoch: 0, train elbo: -5328.4849, validation elbo: -4970.5386, mean time per epoch: 0.3624\n",
            "2025-05-17 11:42:39,351 - INFO - Saved model at /content/drive/MyDrive/Tesi/Alpha/33/runs/eeg_model_0517_1142_38/ckpt/11_42_v0.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Salviamo il modello\n",
            "Chiamiamo lo step di visualizzazione\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-17 11:42:55,534 - INFO - Current number of forward passes: 36\n",
            "2025-05-17 11:42:55,535 - INFO - Epoch: 100, train elbo: -154.9734, validation elbo: -173.9663, mean time per epoch: 0.1539\n",
            "2025-05-17 11:42:55,554 - INFO - Saved model at /content/drive/MyDrive/Tesi/Alpha/33/runs/eeg_model_0517_1142_38/ckpt/11_42_v1.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Salviamo il modello\n",
            "Chiamiamo lo step di visualizzazione\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-17 11:43:03,984 - INFO - Current number of forward passes: 36\n",
            "2025-05-17 11:43:03,985 - INFO - Epoch: 200, train elbo: -50.4869, validation elbo: -51.9933, mean time per epoch: 0.1181\n",
            "2025-05-17 11:43:04,004 - INFO - Saved model at /content/drive/MyDrive/Tesi/Alpha/33/runs/eeg_model_0517_1142_38/ckpt/11_43_v2.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Salviamo il modello\n",
            "Chiamiamo lo step di visualizzazione\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__': #è un costrutto comune in Python usato per controllare se uno script è eseguito direttamente o importato come modulo in un altro script.\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--dev', action='store_true')\n",
        "    parser.add_argument('--epochs', type=int, default=10)\n",
        "    parser.add_argument('--freq', type=int, default=50)\n",
        "    parser.add_argument('--lr', type=float, default=1e-2)\n",
        "    parser.add_argument('--load-dir', type=str, default='')\n",
        "    parser.add_argument('--obs-dim', type=int, default=2)\n",
        "    parser.add_argument('--latent-dim', type=int, default=4)\n",
        "    parser.add_argument('--hidden-dim', type=int, default=20)\n",
        "    parser.add_argument('--rnn-hidden-dim', type=int, default=None)\n",
        "    parser.add_argument('--lstm-hidden-dim', type=int, default=None)\n",
        "    parser.add_argument('--lstm-layers', type=int, default=1)\n",
        "    parser.add_argument('--solver', type=str, default='rk4')\n",
        "    parser.add_argument('--baseline', action='store_true')\n",
        "    combined_channels=1\n",
        "    #window_sizes = [10, 20, 30, 50, 100, 250]\n",
        "    window_sizes=[10]\n",
        "    overlap_percentages = [0, 0.25, 0.5]\n",
        "    subject=\"001\"\n",
        "    condition=\"baseline\"\n",
        "    crossed=False\n",
        "\n",
        "    args = parser.parse_args(args=[])  # Simula l'assenza di input da terminale\n",
        "\n",
        "    # Imposta manualmente i valori desiderati\n",
        "    # Dizionari con gli iperparametri per ogni banda\n",
        "    epochs = {\"Alpha\": 400, \"Low_beta\": 600, \"High_beta\": 600, \"Delta\": 400, \"Theta\": 400}\n",
        "    freq = {\"Alpha\": 100, \"Low_beta\": 100, \"High_beta\": 100, \"Delta\": 100, \"Theta\": 100}\n",
        "    latent_dim = {\"Alpha\": 64, \"Low_beta\": 64, \"High_beta\": 64, \"Delta\": 64, \"Theta\": 64}\n",
        "    hidden_dim = {\"Alpha\": 64, \"Low_beta\": 64, \"High_beta\": 64, \"Delta\": 64, \"Theta\": 64}\n",
        "    lstm_hidden_dim = {\"Alpha\": 64, \"Low_beta\": 64, \"High_beta\": 64, \"Delta\": 64, \"Theta\": 64}\n",
        "    lstm_layers = {\"Alpha\": 2, \"Low_beta\": 2, \"High_beta\": 2, \"Delta\": 2, \"Theta\": 2}\n",
        "    solver = {\"Alpha\": 'rk4', \"Low_beta\": 'rk4', \"High_beta\": 'rk4', \"Delta\": 'rk4', \"Theta\": 'rk4'}\n",
        "    lr= {\"Alpha\": 1e-3, \"Low_beta\": 1e-3, \"High_beta\": 1e-3, \"Delta\": 1e-3, \"Theta\": 1e-3}\n",
        "    #bands = [\"Alpha\", \"Beta\", \"Gamma\", \"Delta\", \"Theta\"]\n",
        "    bands = [\"Alpha\"]\n",
        "\n",
        "    num_channels=33\n",
        "    for window_size in window_sizes:\n",
        "      overlaps = [int(np.ceil(w * window_size)) for w in overlap_percentages]\n",
        "      for overlap in overlaps:\n",
        "    # Loop su tutti i canali\n",
        "        for channel in range(33,num_channels+1):  # Da 1 a num_channels+1\n",
        "          print(\"Canale: \",channel)\n",
        "\n",
        "          for band in bands:\n",
        "            print(\"Sto processando la banda:\", band)\n",
        "            args.epochs = epochs[band]\n",
        "            args.freq = freq[band]\n",
        "            latent_dim = {\"Alpha\": 64, \"Low_beta\": 64, \"High_beta\": 64, \"Delta\": 64, \"Theta\": 64}\n",
        "            epochs = {\"Alpha\": 400, \"Low_beta\": 600, \"High_beta\": 600, \"Delta\": 400, \"Theta\": 400}\n",
        "        #print(\"latent_dim:\", latent_dim, type(latent_dim))  # Debugging\n",
        "            args.latent_dim = latent_dim[band]\n",
        "            args.hidden_dim = hidden_dim[band]\n",
        "            args.lstm_hidden_dim = lstm_hidden_dim[band]\n",
        "            hidden_dim = {\"Alpha\": 64, \"Low_beta\": 64, \"High_beta\": 64, \"Delta\": 64, \"Theta\": 64}\n",
        "            lstm_hidden_dim = {\"Alpha\": 64, \"Low_beta\": 64, \"High_beta\": 64, \"Delta\": 64, \"Theta\": 64}\n",
        "            lstm_layers = {\"Alpha\": 2, \"Low_beta\": 2, \"High_beta\": 2, \"Delta\": 2, \"Theta\": 2}\n",
        "            lr= {\"Alpha\": 1e-3, \"Low_beta\": 1e-3, \"High_beta\": 1e-3, \"Delta\": 1e-3, \"Theta\": 1e-3}\n",
        "            solver = {\"Alpha\": 'rk4', \"Low_beta\": 'rk4', \"High_beta\": 'rk4', \"Delta\": 'rk4', \"Theta\": 'rk4'}\n",
        "            args.lstm_layers = lstm_layers[band]\n",
        "            args.lr = lr[band]\n",
        "            args.solver = solver[band]\n",
        "\n",
        "            tesi_folder = f\"./{band}/{channel}\"\n",
        "            os.makedirs(tesi_folder, exist_ok=True)\n",
        "        #cartella dove voglio salvare i runs\n",
        "        #tesi_folder = f\"./{band}/{channel}\"\n",
        "        #os.makedirs(tesi_folder, exist_ok=True)\n",
        "\n",
        "            runs_folder = os.path.join(tesi_folder, \"runs\")\n",
        "\n",
        "    # Creare la cartella 'runs' dentro 'Tesi' se non esiste\n",
        "            os.makedirs(runs_folder, exist_ok=True)\n",
        "\n",
        "            RUN_TIME = dt.now().strftime(\"%m%d_%H%M_%S\") #genera una stringa con data e ora corrente per identificare in modo univoco una sessione di esecuzione\n",
        "            MODEL_TYPE = 'eeg'\n",
        "            root = runs_folder\n",
        "            save_folder = os.path.join(root, f'{MODEL_TYPE}_model_{RUN_TIME}/')\n",
        "            setup_folders(save_folder)\n",
        "\n",
        "            log_file = f\"{save_folder}logs_{RUN_TIME}.txt\"\n",
        "            logging.basicConfig(\n",
        "              level=logging.DEBUG,\n",
        "              format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
        "                handlers=[\n",
        "                logging.FileHandler(log_file),\n",
        "                logging.StreamHandler()\n",
        "                ]\n",
        "              )\n",
        "            print(f\"Logging salvato in: {log_file}\")\n",
        "\n",
        "            if args.dev:\n",
        "              logging.info('Development run')\n",
        "            else:\n",
        "              logging.info('Production run')\n",
        "\n",
        "        #logging.info(f'Starting {MODEL_TYPE} experiment')\n",
        "        #logging.info(f'Passed arguments: {args}')\n",
        "\n",
        "        # Model parameters\n",
        "            latent_dim = args.latent_dim\n",
        "            nhidden = args.hidden_dim\n",
        "            rnn_nhidden = args.rnn_hidden_dim\n",
        "            lstm_nhidden = args.lstm_hidden_dim\n",
        "            lstm_layers = args.lstm_layers\n",
        "            obs_dim = args.obs_dim\n",
        "\n",
        "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        #logging.info(f'On device {device}')\n",
        "\n",
        "            data = Data.from_func(load_data,\n",
        "                          device=device) #crea un'istanza della classe Data caricando i dati di input e trasferendoli su un dispositivo specifico\n",
        "\n",
        "\n",
        "    #sceglie il modello in base al valore del parametro baseline che è una flag\n",
        "            if not args.baseline:\n",
        "              model = ODEAutoEncoder(data,latent_dim=latent_dim,\n",
        "                               obs_dim=obs_dim,\n",
        "                               rnn_hidden_dim=rnn_nhidden,\n",
        "                               lstm_hidden_dim=lstm_nhidden,\n",
        "                               hidden_dim=nhidden,\n",
        "                               solver=args.solver,\n",
        "                               device=device)\n",
        "            else:\n",
        "              model = LSTMBaseline(input_dim=obs_dim,\n",
        "                             hidden_dim=lstm_nhidden,\n",
        "                             layer_dim=lstm_layers,\n",
        "                             device=device)\n",
        "\n",
        "            stiffness_ratio = model.check_stiffness()\n",
        "            if stiffness_ratio > 1e3:\n",
        "              print(\"Il sistema è probabilmente stiff.\")\n",
        "            else:\n",
        "              print(\"Il sistema non sembra stiff.\")\n",
        "\n",
        "    #ci assicuriamo che il modello sia sul device\n",
        "            model.to(device)\n",
        "\n",
        "            optimizer = optim.Adam(model.get_params(), lr=args.lr) #ottimizzazione di Adam: metodo per aggiornare i pesi minizzando la loss\n",
        "        #logging.info(f\"Optimizer: {optimizer}\")\n",
        "\n",
        "            visualizer = Visualizer(model, data, save_folder=save_folder) #crea un'istanza della classe Visualizer e la assegna alla variabile visualizer.\n",
        "\n",
        "            if args.load_dir != '': #argomento passato da riga di comando che indica il percorso di un checkpoint salvato\n",
        "              if not args.baseline:\n",
        "                model_class = ODEAutoEncoder\n",
        "              else:\n",
        "                model_class = LSTMBaseline\n",
        "\n",
        "              trainer, version = Trainer.from_checkpoint(model_class,\n",
        "                                                   args.load_dir,\n",
        "                                                   args.epochs,\n",
        "                                                   args.freq,\n",
        "                                                   save_folder) #carica un modello addestrato precedentemente e riprende l'allenamento da dove era stato interrotto\n",
        "            else:\n",
        "        #crea un'istanza della classe Trainer, che probabilmente si occupa di gestire l'addestramento del modello.\n",
        "              trainer = Trainer(model=model,\n",
        "                          optim=optimizer,\n",
        "                          data=data,\n",
        "                          visualizer=visualizer,\n",
        "                          epochs=args.epochs,\n",
        "                          freq=args.freq,\n",
        "                          folder=save_folder)\n",
        "\n",
        "              version = 0 #la variabile version serve a tenere traccia della versione del checkpoint quando si riprende l'allenamento da un modello salvato in precedenza\n",
        "\n",
        "            start_time = time.time()\n",
        "            trainer.train(version)  # avvio del training\n",
        "# torch.save(model, \"/content/drive/MyDrive/Tesi/trained_vae_full.pth\")\n",
        "            end_time = time.time()\n",
        "\n",
        "            elapsed_time = end_time - start_time\n",
        "            minutes = int(elapsed_time // 60)\n",
        "            seconds = int(elapsed_time % 60)\n",
        "\n",
        "            print(f\"Training {band} channel {channel} took {minutes} min {seconds} sec\")\n",
        "\n",
        "\n",
        "#torch.save(model.state_dict(),'model_weights.pth')\n",
        "        #logging.info(\"Saving final recontructions\")\n",
        "          if combined_channels==1:\n",
        "            save_dir = f\"./Reconstructions/windowsize{window_size}/overlap{overlap}/SUB{subject}/condition{condition}/band{band}/channel{channel}\"\n",
        "        #save_dir=f\"/content/drive/MyDrive/Tesi/windows/windowsize{window_size}/SUB{subject}/condition{condition}/band{band}/channels_{channel}_{channel+1}_{channel+2}\"\n",
        "\n",
        "        #file_path = f\"{save_dir}/final_reconstruction.npy\"\n",
        "\n",
        "        # Dopo il training\n",
        "        #torch.save(model.state_dict(), f'/content/drive/MyDrive/Tesi/Reconstructions/windowsize{window_size}/overlap{overlap}/SUB{subject}/condition{condition}/band{band}/channel{channel}/model_weights.pth')\n",
        "        #torch.save(model.state_dict(), f'/content/drive/MyDrive/Tesi/Reconstructions/windowsize{window_size}/overlap{overlap}/SUB{subject}/condition{condition}/eeg_{band}/channels_{channel}_{channel+1}_{channel+2}/model_weights.pth')\n",
        "\n",
        "        # Carica la ricostruzione finale salvata dalla cartella Reconstructions locale\n",
        "        #reconstructed_windows = np.load(f\"{save_dir}final_reconstruction_{band}_{channel}.npy\")\n",
        "\n",
        "        #saving(save_dir)\n",
        "            cleanup_after_band_channel(band, channel)\n",
        "            base_path = \".\"\n",
        "\n",
        "            rmse, pearson_corr = compute_val_metrics(base_path, window_size, overlap, subject, condition, band, channel, combined_channels)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Zb-kZ5ifA_Nc",
        "omOWitBCKzBu",
        "t1edH8jfTCnm",
        "s8vsRwwrnoOC",
        "6rDdB__GBblk",
        "GCuQM1Jj_z4R",
        "cIpfThzMUuFZ",
        "JpdhvZeri0qS",
        "8QTbJOeE9TnR",
        "maiIHgxWDeZu",
        "mZiuZ0Apu5p9",
        "bedKbHs9Cccu",
        "z6z_HYv63kva",
        "Acig57-h8QOk",
        "WKUKD-5tkPZP",
        "Hbj_6M_SFsVy",
        "J68K-UOuts4p",
        "kLGaXsizA1Qf",
        "3-OCJMBPxH3r",
        "JFnJyhbQ9Ffv",
        "qZLDBOTY9whJ",
        "8m0JMJEjAeOM",
        "P7pp6NAqCFWE",
        "KIbhCxVi34vu",
        "2xfmwEfQxcxX",
        "ggTlTD7ncHEr",
        "ORNJX9xNC1SI",
        "8D5fBKhPy8BV",
        "0vCgK6B3ATtL",
        "OHwNUfrdDvbs",
        "UFWaFumd2hpR"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
